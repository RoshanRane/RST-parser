{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read the corpus into the list of RSTTree structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get a list of trees to navigate the sentences and to later evaluate them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform s-expression into nested lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "  \n",
    "def parse_sexp(sexp):\n",
    "    \"\"\"\n",
    "    Transform lisp s-expression into nested list structure.\n",
    "    All lisp features except for parentheses are ignored.\n",
    "\n",
    "    Args:\n",
    "        sexp: s-expression to transform.\n",
    "\n",
    "    Returns:\n",
    "        Nested lists representing s-expression.\n",
    "    \"\"\"        \n",
    "\n",
    "    term_regex = r\"\"\"(?mx)\n",
    "        \\s*(?:\n",
    "            (?P<lparen>\\()|\n",
    "            (?P<rparen>\\))|\n",
    "            (?P<s>(\\w|\\-)+)|\n",
    "            (?P<p>[\\.,]+)\n",
    "           )\"\"\"\n",
    "    stack = []\n",
    "    out = []\n",
    "    for termtypes in re.finditer(term_regex, sexp):\n",
    "        term, value = [(t,v) for t,v in termtypes.groupdict().items() if v][0]\n",
    "        if term == 'lparen':\n",
    "            stack.append(out)\n",
    "            out = []\n",
    "        elif term == 'rparen':\n",
    "            assert stack, \"Trouble with nesting of parentheses\"\n",
    "            tmpout, out = out, stack.pop(-1)\n",
    "            out.append(tmpout)\n",
    "        elif term == 's' or term == 'p':\n",
    "            out.append(value)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Error: %r\" % (term, value))\n",
    "    assert not stack, \"Trouble with nesting of parentheses\"\n",
    "    return out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "class RSTTree:\n",
    "    \n",
    "    MONONUCLEAR = 0\n",
    "    MULTINUCLEAR = 1\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.type = 'root'\n",
    "        self.span = None\n",
    "        self.text = None\n",
    "        self.nuclei = []\n",
    "        self.satellite = None\n",
    "        self.is_leaf = False\n",
    "        self.nuclearity = None\n",
    "        self.index = -1\n",
    "        self.relation = None        \n",
    "        self.text_constructed = False\n",
    "        self.flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_list(list_tree, filename, index = -1, parent = None):\n",
    "        \"\"\"\n",
    "        Initialize RST tree from nested lists.\n",
    "\n",
    "        Args:\n",
    "            list_tree: nested lists represeting lisp trees.\n",
    "            filename: name of the file corresponding to the lisp trees.\n",
    "            index: index of the nuclues un multinuclear relations.\n",
    "            parent: parent of this tree.\n",
    "\n",
    "        Returns:\n",
    "            A new RST tree.\n",
    "        \"\"\"\n",
    "\n",
    "        new_tree = RSTTree()\n",
    "        new_tree.parent = parent\n",
    "        new_tree.filename = filename\n",
    "        new_tree.nuclearity = RSTTree.MULTINUCLEAR\n",
    "        new_tree.index = index\n",
    "        \n",
    "        nucleus_index = 0\n",
    "        new_tree.type = list_tree[0].lower()\n",
    "        for child in list_tree[1:]:\n",
    "            child_tag = child[0]\n",
    "            \n",
    "            if child_tag == 'span':\n",
    "                new_tree.span = int(child[1]), int(child[2])\n",
    "            \n",
    "            elif child_tag == 'leaf':\n",
    "                new_tree.is_leaf = True\n",
    "                new_tree.span = int(child[1]), int(child[1])\n",
    "            \n",
    "            elif child_tag == 'rel2par' and parent is not None and child[1] != \"span\":\n",
    "                parent.relation = child[1]\n",
    "            \n",
    "            elif child_tag == 'Nucleus':\n",
    "                new_tree.nuclei.append(RSTTree.from_list(child, filename, parent=new_tree, index=nucleus_index))\n",
    "                nucleus_index += 1\n",
    "            \n",
    "            elif child_tag == 'Satellite':\n",
    "                new_tree.satellite = RSTTree.from_list(child, filename, parent=new_tree)\n",
    "                new_tree.nuclearity = RSTTree.MONONUCLEAR\n",
    "            \n",
    "            elif child_tag == 'text':\n",
    "                new_tree.text = []\n",
    "                for item in child[1:]:\n",
    "                    if isinstance(item, list):\n",
    "                        new_tree.text += item\n",
    "                    else:\n",
    "                        new_tree.text.append(item)\n",
    "\n",
    "        return new_tree\n",
    "\n",
    "    @staticmethod\n",
    "    def from_text(text, start, end):\n",
    "        \"\"\"\n",
    "        Initialize RST tree from text.\n",
    "\n",
    "        Args:\n",
    "            text: as a list of tokens.\n",
    "            start: span starting index.\n",
    "            end: span ending index.\n",
    "\n",
    "        Returns:\n",
    "            A new RST tree.\n",
    "        \"\"\"\n",
    "        new_tree = RSTTree()\n",
    "        new_tree.text = text\n",
    "        new_tree.span = (start, end)\n",
    "        new_tree.is_leaf = True\n",
    "        new_tree.text_constructed = True\n",
    "        return new_tree\n",
    "\n",
    "    @staticmethod\n",
    "    def from_trees(relation, nuclei, satellite=None):\n",
    "        \"\"\"\n",
    "        Initialize RST tree from child trees.\n",
    "\n",
    "        Args:\n",
    "            relation: relation type for this tree.\n",
    "            nuclei: list of child nuclei RST trees.\n",
    "            staellite: child satellite RST tree.\n",
    "\n",
    "        Returns:\n",
    "            A new RST tree.\n",
    "        \"\"\"        \n",
    "        new_tree = RSTTree()\n",
    "        new_tree.is_leaf = False\n",
    "        new_tree.nuclei = nuclei\n",
    "        new_tree.satellite = satellite\n",
    "        new_tree.relation = relation\n",
    "        new_tree.nuclearity = RSTTree.MULTINUCLEAR if satellite is None else RSTTree.MONONUCLEAR\n",
    "        new_tree.calculate_spans()\n",
    "        \n",
    "        for nucleus in new_tree.nuclei:\n",
    "            nucleus.type = 'nucleus'\n",
    "            nucleus.parent = new_tree\n",
    "        \n",
    "        if new_tree.satellite is not None:\n",
    "            new_tree.satellite.type = 'satellite'\n",
    "            new_tree.satellite.parent = new_tree\n",
    "        \n",
    "        return new_tree\n",
    "\n",
    "    def output_lisp(self, indent = 0):\n",
    "        \"\"\"\n",
    "        Output the tree in the s-expression format.\n",
    "\n",
    "        Args:\n",
    "            indent: indentation for the output.\n",
    "\n",
    "        Returns:\n",
    "            A pretty string containing s-expression.\n",
    "        \"\"\"        \n",
    "\n",
    "        rep = (\" \" * indent) + \"( \" + self.type + \" \"\n",
    "        # 1. leaf or span\n",
    "        if self.is_leaf:\n",
    "            rep += \"(leaf \" + str(self.span[0]) + \") \"\n",
    "        else:\n",
    "            rep += \"(span \" + str(self.span[0]) + \" \" + str(self.span[1]) + \") \"\n",
    "        # 2. rel2par\n",
    "        if self.type == \"nucleus\":\n",
    "            if self.parent.nuclearity == RSTTree.MULTINUCLEAR:\n",
    "                rep += \"(rel2par \" + self.parent.relation + \") \"\n",
    "            else:\n",
    "                rep += \"(rel2par span) \"\n",
    "        elif self.type == \"satellite\":\n",
    "            rep += \"(rel2par \" + self.parent.relation + \") \"\n",
    "        # 3. children\n",
    "        if self.is_leaf:\n",
    "            rep += \"(text \" + \" \".join(self.text) + \") )\"\n",
    "        else:\n",
    "            for nucleus in self.nuclei:\n",
    "                rep += (\" \" * indent) + \"\\n\" + nucleus.output_lisp(indent + 2)\n",
    "            if self.satellite is not None:\n",
    "                rep += (\" \" * indent) + \"\\n\" + self.satellite.output_lisp(indent + 2)\n",
    "            rep += (\" \" * indent) + \"\\n)\"\n",
    "        return rep\n",
    "    \n",
    "    def calculate_spans(self):\n",
    "        if self.span is None:\n",
    "            start = np.inf\n",
    "            end = 0\n",
    "            if self.nuclei is not None:\n",
    "                start = min([nucleus.calculate_spans()[0] for nucleus in self.nuclei])\n",
    "                end = max([nucleus.calculate_spans()[1] for nucleus in self.nuclei])\n",
    "            if self.satellite is not None:\n",
    "                start = min(start, self.satellite.calculate_spans()[0])\n",
    "                end = max(end, self.satellite.calculate_spans()[1])\n",
    "            self.span = (start, end)\n",
    "        return self.span\n",
    "        \n",
    "    def construct_text(self):\n",
    "        self.text_constructed = True\n",
    "        if self.text is None:\n",
    "            texts = []\n",
    "            if self.nuclei is not None:\n",
    "                texts += [nucleus.construct_text() for nucleus in self.nuclei]\n",
    "            if self.satellite is not None:\n",
    "                texts.append(self.satellite.construct_text())\n",
    "            self.text = list(itertools.chain.from_iterable(texts))\n",
    "        return self.text\n",
    "\n",
    "    def get_subtexts(self):\n",
    "        assert self.text_constructed, \"Texts are not constructed\"\n",
    "        subtexts = []\n",
    "        if not self.is_leaf:\n",
    "            if self.nuclei is not None:\n",
    "                subtexts += [nucleus.text for nucleus in self.nuclei]\n",
    "            if self.satellite is not None:\n",
    "                subtexts.append(self.satellite.text)\n",
    "        return subtexts\n",
    "    \n",
    "    def all_trees(self):\n",
    "        subtrees = []\n",
    "        if self.nuclei is not None:\n",
    "            subtrees += [nucleus.all_trees() for nucleus in self.nuclei]\n",
    "        if self.satellite is not None:\n",
    "            subtrees.append(self.satellite.all_trees())\n",
    "        subtrees = self.flatten(subtrees)\n",
    "        if not self.is_leaf:\n",
    "            subtrees.append(self)\n",
    "        return subtrees\n",
    "\n",
    "    def all_edus(self):\n",
    "        if self.text is not None:\n",
    "            return [self.text]\n",
    "        else:\n",
    "            edus = []\n",
    "            edus += [nucleus.all_edus() for nucleus in self.nuclei]\n",
    "            if self.satellite is not None:\n",
    "                edus += self.satellite.all_edus()\n",
    "            return edus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class CorpusReader:\n",
    "\n",
    "    def __init__(self, rst_root):\n",
    "        self.rst_root = rst_root\n",
    "    \n",
    "    def load_test_trees(self):\n",
    "        return self._load_trees(\"TEST\")\n",
    "    \n",
    "    def load_train_trees(self):\n",
    "        return self._load_trees(\"TRAINING\")\n",
    "    \n",
    "    def _load_trees(self, dirsuffix):\n",
    "        root_with_suffix = os.path.join(self.rst_root, dirsuffix)\n",
    "        for dirname in os.listdir(root_with_suffix):\n",
    "            dirname = os.path.join(root_with_suffix, dirname)\n",
    "            if os.path.isdir(dirname):\n",
    "                for filename in os.listdir(dirname):\n",
    "                    filename = os.path.join(dirname, filename)\n",
    "                    if os.path.isfile(filename) and len(filename) > 9 and filename[-9:] == \"lisp.name\":\n",
    "                        with open(filename, encoding=\"utf-8\") as file:\n",
    "                            try:\n",
    "                                contents = parse_sexp(file.read())\n",
    "                            except AssertionError as err:\n",
    "                                print(filename)\n",
    "                                raise err\n",
    "                            tree = RSTTree.from_list(contents, filename)\n",
    "                            tree.construct_text()\n",
    "                            yield tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_reader = CorpusReader(\"/Users/vpraid/Downloads/RSTDT/data/RSTtrees-WSJ-main-1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Use gensim to transform sentences into word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create EDU reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EduReader:\n",
    "    \n",
    "    def __init__(self, reader):\n",
    "        self.reader = reader\n",
    "\n",
    "    def __iter__(self):\n",
    "        for tree in self.reader.load_train_trees():\n",
    "            for edu in tree.all_edus():\n",
    "                yield edu\n",
    "\n",
    "edu_reader = EduReader(corpus_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load gensim and create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_SIZE=100\n",
    "embed_model = gensim.models.Word2Vec(edu_reader, size=EMBED_SIZE, min_count=2, window=5, iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result embedding shape: (7505, 100)\n",
      "Checking similar words:\n",
      "  money -> approach (0.42), choice (0.39), mega-issues (0.37), buying (0.36)\n",
      "  bank -> RTC (0.43), Parisian (0.41), Weatherford (0.41), suspension (0.41)\n",
      "  company -> transaction (0.42), firm (0.39), group (0.39), companies (0.38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \n",
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "def check_similar(model):\n",
    "    pretrained_weights = model.wv.syn0\n",
    "    vocab_size, emdedding_size = pretrained_weights.shape\n",
    "    print('Result embedding shape:', pretrained_weights.shape)\n",
    "    print('Checking similar words:')\n",
    "    for word in ['money', 'bank', 'company']:\n",
    "        most_similar = ', '.join('%s (%.2f)' % (similar, dist) for similar, dist in model.most_similar(word)[:4])\n",
    "        print('  %s -> %s' % (word, most_similar))\n",
    "\n",
    "check_similar(embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence):\n",
    "        embeddings = [embed_model[word] for word in sentence if word in embed_model.wv.vocab]\n",
    "        if len(embeddings) == 0:\n",
    "            return None\n",
    "        word_sum = np.zeros(EMBED_SIZE, dtype='float64')\n",
    "        word_count = 0\n",
    "        for word in embeddings:\n",
    "            word_sum += word\n",
    "            word_count += 1\n",
    "        return word_sum / word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get POS tags from spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.attrs import POS\n",
    "\n",
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos2idx = {}\n",
    "def fill_pos_tags():\n",
    "    for edu in edu_reader:\n",
    "        doc = nlp(\" \".join(edu))\n",
    "        for token in doc:\n",
    "            if token.pos_ not in pos2idx:\n",
    "                pos2idx[token.pos_] = len(pos2idx)\n",
    "\n",
    "fill_pos_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vector(sentence):\n",
    "    embedding = get_sentence_embedding(sentence)\n",
    "    if embedding is None:\n",
    "        return None\n",
    "    doc = nlp(\" \".join(sentence))\n",
    "    root = [token for token in doc if token.head == token][0]\n",
    "    return np.r_[len(sentence), (np.arange(POS) == pos2idx[root.pos_]).astype(np.float64), embedding]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train connection classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "\n",
    "tqdm.monitor_interval = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_connected(lhs, rhs):\n",
    "    if lhs.parent != rhs.parent:\n",
    "        return False\n",
    "    if lhs.parent.nuclearity == RSTTree.MONONUCLEAR:\n",
    "        return True\n",
    "    assert lhs.type == 'nucleus' and rhs.type == 'nucleus'\n",
    "    return np.abs(lhs.index - rhs.index) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from random import shuffle\n",
    "\n",
    "def shuffled(x):\n",
    "    y = x[:]\n",
    "    shuffle(y)\n",
    "    return y\n",
    "\n",
    "def get_vector(lhs, rhs):\n",
    "    if lhs.text is None or rhs.text is None:\n",
    "        return None\n",
    "    lhs_vector = get_sentence_vector(lhs.text)\n",
    "    if lhs_vector is None:\n",
    "        return None\n",
    "    rhs_vector = get_sentence_vector(rhs.text)\n",
    "    if rhs_vector is None:\n",
    "        return None\n",
    "    return np.r_[lhs_vector, rhs_vector]\n",
    "\n",
    "def get_connection_set(trees):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    for tree in tqdm_notebook(trees):\n",
    "        \n",
    "        subtrees = tree.all_trees()\n",
    "        for subtree in subtrees:\n",
    "            if subtree.nuclearity == RSTTree.MONONUCLEAR:\n",
    "                pair = get_vector(subtree.nuclei[0], subtree.satellite)\n",
    "                if pair is None:\n",
    "                    continue\n",
    "                pairs.append(pair)\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                for lhs, rhs in zip(subtree.nuclei, subtree.nuclei[1:]):\n",
    "                    pair = get_vector(lhs, rhs)\n",
    "                    if pair is None:\n",
    "                        continue\n",
    "                    pairs.append(pair)\n",
    "                    labels.append(1)\n",
    "\n",
    "        for i, (left, right) in enumerate(product(shuffled(subtrees), shuffled(subtrees))):\n",
    "            if left == right or are_connected(left, right):\n",
    "                continue\n",
    "            if i > 30:\n",
    "                break\n",
    "            pair = get_vector(left, right)\n",
    "            if pair is None:\n",
    "                continue\n",
    "            pairs.append(pair)\n",
    "            labels.append(0)\n",
    "\n",
    "    shape = len(pairs), pairs[0].shape[0]\n",
    "    return np.concatenate(pairs).reshape(shape), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training connection data\n",
    "Do not run this cell unless you know what you are doing. It takes 10 minutes to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563decc19fbe4ddaa02346dbc17a6c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conn_train_X, conn_train_Y = get_connection_set(corpus_reader.load_train_trees())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / load training connection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('connection_train_set.pickle', 'wb') as handle:\n",
    "    pickle.dump((conn_train_X, conn_train_Y), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('connection_train_set.pickle', 'rb') as handle:\n",
    "    (conn_train_X, conn_train_Y) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test connection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c150cbaf76594f1b956fbd754c7ccfee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conn_test_X, conn_test_Y = get_connection_set(corpus_reader.load_test_trees())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / load test connection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('connection_test_set.pickle', 'wb') as handle:\n",
    "    pickle.dump((conn_test_X, conn_test_Y), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('connection_test_set.pickle', 'rb') as handle:\n",
    "    (conn_test_X, conn_test_Y) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_model = Sequential()\n",
    "connection_model.add(Dense(256, input_dim=conn_train_X.shape[1], activation='relu'))\n",
    "connection_model.add(Dropout(0.5))\n",
    "connection_model.add(Dense(128, activation='relu'))\n",
    "connection_model.add(Dropout(0.5))\n",
    "connection_model.add(Dense(64, activation='relu'))\n",
    "connection_model.add(Dropout(0.5))\n",
    "connection_model.add(Dense(1, activation='sigmoid'))\n",
    "connection_model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_model.fit(conn_train_X, conn_train_Y, batch_size=128, verbose=0, epochs=15)\n",
    "connection_model.save(\"connection_model.hs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or just load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_model = load_model(\"connection_model.hs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21345597905274691, 0.90359750197906585]\n"
     ]
    }
   ],
   "source": [
    "score = connection_model.evaluate(conn_train_X, conn_train_Y, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1005296130025364, 0.75411089853620439]\n"
     ]
    }
   ],
   "source": [
    "score = connection_model.evaluate(conn_test_X, conn_test_Y, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train relation classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "def get_relation_set(trees, populate_relations = False, relation2idx = dict()):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    for tree in tqdm_notebook(trees):\n",
    "        \n",
    "        subtrees = tree.all_trees()\n",
    "        for subtree in subtrees:\n",
    "            \n",
    "            if subtree.relation is None:\n",
    "                continue\n",
    "            \n",
    "            if populate_relations and subtree.relation not in relation2idx:\n",
    "                relation2idx[subtree.relation] = len(relation2idx)\n",
    "            \n",
    "            elif not populate_relations and subtree.relation not in relation2idx.keys():\n",
    "                continue\n",
    "            \n",
    "            if subtree.nuclearity == RSTTree.MONONUCLEAR:\n",
    "                pair = get_vector(subtree.nuclei[0], subtree.satellite)\n",
    "                if pair is None:\n",
    "                    continue\n",
    "                pairs.append(pair)\n",
    "                labels.append(relation2idx[subtree.relation])\n",
    "            \n",
    "            else:\n",
    "                for lhs, rhs in zip(subtree.nuclei, subtree.nuclei[1:]):\n",
    "                    pair = get_vector(lhs, rhs)\n",
    "                    if pair is None:\n",
    "                        continue\n",
    "                    pairs.append(pair)\n",
    "                    labels.append(relation2idx[subtree.relation])\n",
    "\n",
    "    shape = len(pairs), pairs[0].shape[0]\n",
    "    return np.concatenate(pairs).reshape(shape), to_categorical(labels, num_classes=len(relation2idx)), relation2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training relation data\n",
    "Do not run this cell unless you know what you are doing. It takes 10 minutes to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a446db9eb844599cd3d4337436d175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rel_train_X, rel_train_Y, relation2idx = get_relation_set(corpus_reader.load_train_trees(), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / load training relation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('relation_train_set.pickle', 'wb') as handle:\n",
    "    pickle.dump((rel_train_X, rel_train_Y, relation2idx), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('relation_train_set.pickle', 'rb') as handle:\n",
    "    (rel_train_X, rel_train_Y, relation2idx) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test relation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710000b8226440e9a5ddeedef2c849d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rel_test_X, rel_test_Y, _ = get_relation_set(\n",
    "    corpus_reader.load_test_trees(),\n",
    "    populate_relations=False,\n",
    "    relation2idx=relation2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / load test relation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('relation_test_set.pickle', 'wb') as handle:\n",
    "    pickle.dump((rel_test_X, rel_test_Y), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('relation_test_set.pickle', 'rb') as handle:\n",
    "    (rel_test_X, rel_test_Y) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_model = Sequential()\n",
    "relation_model.add(Dense(256, input_dim=rel_train_X.shape[1], activation='relu'))\n",
    "relation_model.add(Dropout(0.5))\n",
    "relation_model.add(Dense(128, activation='relu'))\n",
    "relation_model.add(Dropout(0.5))\n",
    "relation_model.add(Dense(64, activation='relu'))\n",
    "relation_model.add(Dropout(0.5))\n",
    "relation_model.add(Dense(rel_train_Y.shape[1], activation='softmax'))\n",
    "relation_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_model.fit(rel_train_X, rel_train_Y, batch_size=128, verbose=0, epochs=50)\n",
    "relation_model.save(\"relation_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or just load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_model = load_model(\"relation_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.785708257890628, 0.53254663115179401]\n"
     ]
    }
   ],
   "source": [
    "score = relation_model.evaluate(rel_train_X, rel_train_Y, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5126443585398879, 0.41736334399395053]\n"
     ]
    }
   ],
   "source": [
    "score = relation_model.evaluate(rel_test_X, rel_test_Y, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train nuclearity classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUCLEUS_L = [1, 0]\n",
    "NUCLEUS_R = [0, 1]\n",
    "NUCLEUS_B = [1, 1]\n",
    "\n",
    "def get_nuclearity_set(trees):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    for tree in tqdm_notebook(trees):\n",
    "        \n",
    "        subtrees = tree.all_trees()\n",
    "        for subtree in subtrees:\n",
    "            \n",
    "            if subtree.nuclearity == RSTTree.MONONUCLEAR:\n",
    "                pair = get_vector(subtree.nuclei[0], subtree.satellite)\n",
    "                if pair is None:\n",
    "                    continue\n",
    "                pairs.append(pair)\n",
    "                label = NUCLEUS_L if subtree.nuclei[0].span[1] <= subtree.satellite.span[0] else NUCLEUS_R\n",
    "                labels.append(label)\n",
    "            \n",
    "            else:\n",
    "                for lhs, rhs in zip(subtree.nuclei, subtree.nuclei[1:]):\n",
    "                    pair = get_vector(lhs, rhs)\n",
    "                    if pair is None:\n",
    "                        continue\n",
    "                    pairs.append(pair)\n",
    "                    labels.append(NUCLEUS_B)\n",
    "\n",
    "    shape = len(pairs), pairs[0].shape[0]\n",
    "    return np.concatenate(pairs).reshape(shape), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare nuclearity relation data\n",
    "Do not run this cell unless you know what you are doing. It takes 10 minutes to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89047e115844c8ab1b598cfdae31dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nuc_train_X, nuc_train_Y = get_nuclearity_set(corpus_reader.load_train_trees())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / load nuclearity training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nuclearity_train_set.pickle', 'wb') as handle:\n",
    "    pickle.dump((nuc_train_X, nuc_train_Y), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nuclearity_train_set.pickle', 'rb') as handle:\n",
    "    (nuc_train_X, nuc_train_Y) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare nuclearity test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150d2876d4ea462ca2b22ad0bbdb00a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nuc_test_X, nuc_test_Y = get_nuclearity_set(corpus_reader.load_test_trees())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / load nuclearity test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nuclearity_test_set.pickle', 'wb') as handle:\n",
    "    pickle.dump((nuc_test_X, nuc_test_Y), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nuclearity_test_set.pickle', 'rb') as handle:\n",
    "    (nuc_test_X, nuc_test_Y) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclearity_model = Sequential()\n",
    "nuclearity_model.add(Dense(256, input_dim=nuc_train_X.shape[1], activation='relu'))\n",
    "nuclearity_model.add(Dropout(0.5))\n",
    "nuclearity_model.add(Dense(128, activation='relu'))\n",
    "nuclearity_model.add(Dropout(0.5))\n",
    "nuclearity_model.add(Dense(64, activation='relu'))\n",
    "nuclearity_model.add(Dropout(0.5))\n",
    "nuclearity_model.add(Dense(nuc_train_Y.shape[1], activation='softmax'))\n",
    "nuclearity_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclearity_model.fit(nuc_train_X, nuc_train_Y, batch_size=128, verbose=0, epochs=10)\n",
    "nuclearity_model.save(\"nuclearity_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or just load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclearity_model = load_model(\"nuclearity_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50873765834370721, 0.95097068899885806]\n"
     ]
    }
   ],
   "source": [
    "score = nuclearity_model.evaluate(nuc_train_X, nuc_train_Y, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62963520883748714, 0.91784338911323404]\n"
     ]
    }
   ],
   "source": [
    "score = nuclearity_model.evaluate(nuc_test_X, nuc_test_Y, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Tree construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = ['Spencer', 'J', '.', 'Volk', ',', 'president', 'and', 'chief', 'operating', 'officer', 'of', 'this', 'consumer', 'and', 'industrial', 'products', 'company', ',', 'was', 'elected', 'a', 'director', '.']\n",
    "sent2 = ['Mr', '.', 'Volk', ',', '55', 'years', 'old', ',', 'succeeds', 'Duncan', 'Dwight', ',']\n",
    "sent3 = ['who', 'retired', 'in', 'September', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2relation = { index : relation for relation, index in relation2idx.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_once(tree_list):\n",
    "    best_connection = 0\n",
    "    best_connection_index = -1\n",
    "    best_vector = None\n",
    "    for i, (lhs, rhs) in enumerate(zip(tree_list, tree_list[1:])):\n",
    "        vector = get_vector(lhs, rhs)\n",
    "        if vector is None:\n",
    "            continue\n",
    "        connection = connection_model.predict(np.expand_dims(vector, axis=0))[0][0]\n",
    "        #print(connection)\n",
    "        if connection > best_connection:\n",
    "            best_connection = connection\n",
    "            best_connection_index = i\n",
    "            best_vector = vector\n",
    "\n",
    "    if best_vector is None:\n",
    "        return tree_list\n",
    "\n",
    "    lhs = tree_list[best_connection_index]\n",
    "    rhs = tree_list[best_connection_index + 1]\n",
    "\n",
    "    relation = relation_model.predict_classes(np.expand_dims(best_vector, axis=0))[0]\n",
    "    relation = idx2relation[relation]\n",
    "    #print(relation)\n",
    "\n",
    "    nuclearity = nuclearity_model.predict(np.expand_dims(best_vector, axis=0))[0]\n",
    "    nuclearity = np.round(nuclearity).astype(np.int)\n",
    "    #print(nuclearity)\n",
    "\n",
    "    nuclei = []\n",
    "    satellite = None\n",
    "    if nuclearity[0] == 0:\n",
    "        satellite = lhs\n",
    "    else:\n",
    "        nuclei.append(lhs)\n",
    "    if nuclearity[1] == 0:\n",
    "        satellite = rhs\n",
    "    else:\n",
    "        nuclei.append(rhs)\n",
    "\n",
    "    new_tree = RSTTree.from_trees(relation, nuclei, satellite)\n",
    "    new_tree.construct_text()\n",
    "    new_tree_list = tree_list[:best_connection_index]\n",
    "    new_tree_list.append(new_tree)\n",
    "    new_tree_list += tree_list[best_connection_index + 2:]\n",
    "    return new_tree_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_list = [RSTTree.from_text(sent1, 1, 1),\n",
    "             RSTTree.from_text(sent2, 2, 2),\n",
    "             RSTTree.from_text(sent3, 3, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(tree_list):\n",
    "    prev_length = len(tree_list)\n",
    "    while True:\n",
    "        tree_list = merge_once(tree_list)\n",
    "        if len(tree_list) == prev_length:\n",
    "            return tree_list\n",
    "        prev_length = len(tree_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( root (span 1 3) \n",
      "  ( nucleus (span 1 2) (rel2par span)   \n",
      "    ( nucleus (leaf 1) (rel2par span) (text Spencer J . Volk , president and chief operating officer of this consumer and industrial products company , was elected a director .) )  \n",
      "    ( satellite (leaf 2) (rel2par elaboration-additional) (text Mr . Volk , 55 years old , succeeds Duncan Dwight ,) )  \n",
      ")\n",
      "  ( satellite (leaf 3) (rel2par elaboration-additional) (text who retired in September .) )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "result = merge(tree_list)\n",
    "print(result[0].output_lisp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
