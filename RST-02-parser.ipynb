<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read the corpus into the list of RSTTree structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get a list of trees to navigate the sentences and to later evaluate them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform s-expression into nested lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "  \n",
    "def parse_sexp(sexp):\n",
    "    term_regex = r\"\"\"(?mx)\n",
    "        \\s*(?:\n",
    "            (?P<lparen>\\()|\n",
    "            (?P<rparen>\\))|\n",
    "            (?P<s>(\\w|\\-)+)|\n",
    "            (?P<p>[\\.,]+)\n",
    "           )\"\"\"\n",
    "    stack = []\n",
    "    out = []\n",
    "    for termtypes in re.finditer(term_regex, sexp):\n",
    "        term, value = [(t,v) for t,v in termtypes.groupdict().items() if v][0]\n",
    "        if term == 'lparen':\n",
    "            stack.append(out)\n",
    "            out = []\n",
    "        elif term == 'rparen':\n",
    "            assert stack, \"Trouble with nesting of parens\"\n",
    "            tmpout, out = out, stack.pop(-1)\n",
    "            out.append(tmpout)\n",
    "        elif term == 's' or term == 'p':\n",
    "            out.append(value)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Error: %r\" % (term, value))\n",
    "    assert not stack, \"Trouble with nesting of brackets\"\n",
    "    return out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1432,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "class RSTTree:\n",
    "    \n",
    "    MONONUCLEAR = 0\n",
    "    MULTINUCLEAR = 1\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.type = 'root'\n",
    "        self.span = None\n",
    "        self.text = None\n",
    "        self.nuclei = []\n",
    "        self.satellite = None\n",
    "        self.is_leaf = False\n",
    "        self.nuclearity = None\n",
    "        self.index = -1\n",
    "        self.relation = None        \n",
    "        self.text_constructed = False\n",
    "        self.flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_list(list_tree, filename, index = -1, parent = None):\n",
    "\n",
    "        new_tree = RSTTree()\n",
    "        new_tree.parent = parent\n",
    "        new_tree.filename = filename\n",
    "        new_tree.nuclearity = RSTTree.MULTINUCLEAR\n",
    "        new_tree.index = index\n",
    "        \n",
    "        nucleus_index = 0\n",
    "        new_tree.type = list_tree[0].lower()\n",
    "        for child in list_tree[1:]:\n",
    "            child_tag = child[0]\n",
    "            \n",
    "            if child_tag == 'span':\n",
    "                new_tree.span = int(child[1]), int(child[2])\n",
    "            \n",
    "            elif child_tag == 'leaf':\n",
    "                new_tree.is_leaf = True\n",
    "                new_tree.span = int(child[1]), int(child[1])\n",
    "            \n",
    "            elif child_tag == 'rel2par' and parent is not None and child[1] != \"span\":\n",
    "                parent.relation = child[1]\n",
    "            \n",
    "            elif child_tag == 'Nucleus':\n",
    "                new_tree.nuclei.append(RSTTree.from_list(child, filename, parent=new_tree, index=nucleus_index))\n",
    "                nucleus_index += 1\n",
    "            \n",
    "            elif child_tag == 'Satellite':\n",
    "                new_tree.satellite = RSTTree.from_list(child, filename, parent=new_tree)\n",
    "                new_tree.nuclearity = RSTTree.MONONUCLEAR\n",
    "            \n",
    "            elif child_tag == 'text':\n",
    "                new_tree.text = []\n",
    "                for item in child[1:]:\n",
    "                    if isinstance(item, list):\n",
    "                        new_tree.text += item\n",
    "                    else:\n",
    "                        new_tree.text.append(item)\n",
    "\n",
    "        return new_tree\n",
    "\n",
    "    @staticmethod\n",
    "    def from_text(text, start, end):\n",
    "        new_tree = RSTTree()\n",
    "        new_tree.text = text\n",
    "        new_tree.span = (start, end)\n",
    "        new_tree.is_leaf = True\n",
    "        new_tree.text_constructed = True\n",
    "        return new_tree\n",
    "\n",
    "    @staticmethod\n",
    "    def from_trees(relation, nuclei, satellite=None):\n",
    "        \n",
    "        new_tree = RSTTree()\n",
    "        new_tree.is_leaf = False\n",
    "        new_tree.nuclei = nuclei\n",
    "        new_tree.satellite = satellite\n",
    "        new_tree.relation = relation\n",
    "        new_tree.nuclearity = RSTTree.MULTINUCLEAR if satellite is None else RSTTree.MONONUCLEAR\n",
    "        new_tree.calculate_spans()\n",
    "        \n",
    "        for nucleus in new_tree.nuclei:\n",
    "            nucleus.type = 'nucleus'\n",
    "            nucleus.parent = new_tree\n",
    "        \n",
    "        if new_tree.satellite is not None:\n",
    "            new_tree.satellite.type = 'satellite'\n",
    "            new_tree.satellite.parent = new_tree\n",
    "        \n",
    "        return new_tree\n",
    "\n",
    "    def output_lisp(self, indent = 0):\n",
    "        rep = (\" \" * indent) + \"( \" + self.type + \" \"\n",
    "        # 1. leaf or span\n",
    "        if self.is_leaf:\n",
    "            rep += \"(leaf \" + str(self.span[0]) + \") \"\n",
    "        else:\n",
    "            rep += \"(span \" + str(self.span[0]) + \" \" + str(self.span[1]) + \") \"\n",
    "        # 2. rel2par\n",
    "        if self.type == \"nucleus\":\n",
    "            if self.parent.nuclearity == RSTTree.MULTINUCLEAR:\n",
    "                rep += \"(rel2par \" + self.parent.relation + \") \"\n",
    "            else:\n",
    "                rep += \"(rel2par span) \"\n",
    "        elif self.type == \"satellite\":\n",
    "            rep += \"(rel2par \" + self.parent.relation + \") \"\n",
    "        # 3. children\n",
    "        if self.is_leaf:\n",
    "            rep += \"(text \" + \" \".join(self.text) + \") )\"\n",
    "        else:\n",
    "            for nucleus in self.nuclei:\n",
    "                rep += (\" \" * indent) + \"\\n\" + nucleus.output_lisp(indent + 2)\n",
    "            if self.satellite is not None:\n",
    "                rep += (\" \" * indent) + \"\\n\" + self.satellite.output_lisp(indent + 2)\n",
    "            rep += (\" \" * indent) + \"\\n)\"\n",
    "        return rep\n",
    "    \n",
    "    def calculate_spans(self):\n",
    "        if self.span is None:\n",
    "            start = np.inf\n",
    "            end = 0\n",
    "            if self.nuclei is not None:\n",
    "                start = min([nucleus.calculate_spans()[0] for nucleus in self.nuclei])\n",
    "                end = max([nucleus.calculate_spans()[1] for nucleus in self.nuclei])\n",
    "            if self.satellite is not None:\n",
    "                start = min(start, self.satellite.calculate_spans()[0])\n",
    "                end = max(end, self.satellite.calculate_spans()[1])\n",
    "            self.span = (start, end)\n",
    "        return self.span\n",
    "        \n",
    "    def construct_text(self):\n",
    "        self.text_constructed = True\n",
    "        if self.text is None:\n",
    "            texts = []\n",
    "            if self.nuclei is not None:\n",
    "                texts += [nucleus.construct_text() for nucleus in self.nuclei]\n",
    "            if self.satellite is not None:\n",
    "                texts.append(self.satellite.construct_text())\n",
    "            self.text = list(itertools.chain.from_iterable(texts))\n",
    "        return self.text\n",
    "\n",
    "    def get_subtexts(self):\n",
    "        assert self.text_constructed, \"Texts are not constructed\"\n",
    "        subtexts = []\n",
    "        if not self.is_leaf:\n",
    "            if self.nuclei is not None:\n",
    "                subtexts += [nucleus.text for nucleus in self.nuclei]\n",
    "            if self.satellite is not None:\n",
    "                subtexts.append(self.satellite.text)\n",
    "        return subtexts\n",
    "    \n",
    "    def all_trees(self):\n",
    "        subtrees = []\n",
    "        if self.nuclei is not None:\n",
    "            subtrees += [nucleus.all_trees() for nucleus in self.nuclei]\n",
    "        if self.satellite is not None:\n",
    "            subtrees.append(self.satellite.all_trees())\n",
    "        subtrees = self.flatten(subtrees)\n",
    "        if not self.is_leaf:\n",
    "            subtrees.append(self)\n",
    "        return subtrees\n",
    "\n",
    "    def all_edus(self):\n",
    "        if self.text is not None:\n",
    "            return [self.text]\n",
    "        else:\n",
    "            edus = []\n",
    "            edus += [nucleus.all_edus() for nucleus in self.nuclei]\n",
    "            if self.satellite is not None:\n",
    "                edus += self.satellite.all_edus()\n",
    "            return edus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "metadata": {},
   "outputs": [],
   "source": [
    "sexp = \"\"\"\n",
    "( Root (span 1 3) (prom 1)\n",
    "   ( Nucleus (leaf 1) (rel2par span) (prom 1) (text  Spencer J. Volk, president and chief operating officer of this consumer and industrial products company, was elected a director.) )\n",
    "   ( Satellite (span 2 3) (rel2par elaboration-additional) (prom 2)\n",
    "      ( Nucleus (leaf 2) (rel2par span) (prom 2) (text  Mr. Volk, 55 years old, succeeds Duncan Dwight,) )\n",
    "      ( Satellite (leaf 3) (rel2par elaboration-additional-e) (prom 3) (text (who retired in September.)) )\n",
    "   )\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "parsed = parse_sexp(sexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( root (span 1 3) \n",
      "  ( nucleus (leaf 1) (rel2par span) (text Spencer J . Volk , president and chief operating officer of this consumer and industrial products company , was elected a director .) )\n",
      "  ( satellite (span 2 3) (rel2par elaboration-additional)   \n",
      "    ( nucleus (leaf 2) (rel2par span) (text Mr . Volk , 55 years old , succeeds Duncan Dwight ,) )  \n",
      "    ( satellite (leaf 3) (rel2par elaboration-additional-e) (text who retired in September .) )  \n",
      ")\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "root = RSTTree.from_list(parsed, \"bbb\")\n",
    "_ = root.construct_text()\n",
    "lisp = root.output_lisp()\n",
    "print(lisp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class CorpusReader:\n",
    "\n",
    "    def __init__(self, rst_root):\n",
    "        self.rst_root = rst_root\n",
    "    \n",
    "    def load_test_trees(self):\n",
    "        return self._load_trees(\"TEST\")\n",
    "    \n",
    "    def load_train_trees(self):\n",
    "        return self._load_trees(\"TRAINING\")\n",
    "    \n",
    "    def _load_trees(self, dirsuffix):\n",
    "        root_with_suffix = os.path.join(self.rst_root, dirsuffix)\n",
    "        for dirname in os.listdir(root_with_suffix):\n",
    "            dirname = os.path.join(root_with_suffix, dirname)\n",
    "            if os.path.isdir(dirname):\n",
    "                for filename in os.listdir(dirname):\n",
    "                    filename = os.path.join(dirname, filename)\n",
    "                    if os.path.isfile(filename) and len(filename) > 9 and filename[-9:] == \"lisp.name\":\n",
    "                        with open(filename, encoding=\"utf-8\") as file:\n",
    "                            try:\n",
    "                                contents = parse_sexp(file.read())\n",
    "                            except AssertionError as err:\n",
    "                                print(filename)\n",
    "                                raise err\n",
    "                            tree = RSTTree.from_list(contents, filename)\n",
    "                            tree.construct_text()\n",
    "                            yield tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_reader = CorpusReader(\"/Users/vpraid/Downloads/RSTDT/data/RSTtrees-WSJ-main-1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Use gensim to transform sentences into word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create EDU reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EduReader:\n",
    "    \n",
    "    def __init__(self, reader):\n",
    "        self.reader = reader\n",
    "\n",
    "    def __iter__(self):\n",
    "        for tree in self.reader.load_train_trees():\n",
    "            for edu in tree.all_edus():\n",
    "                yield edu\n",
    "\n",
    "edu_reader = EduReader(corpus_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load gensim and create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-03 18:47:10,230 : INFO : collecting all words and their counts\n",
      "2018-03-03 18:47:10,278 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-03 18:47:15,401 : INFO : collected 14750 word types from a corpus of 146505 raw words and 347 sentences\n",
      "2018-03-03 18:47:15,402 : INFO : Loading a fresh vocabulary\n",
      "2018-03-03 18:47:15,448 : INFO : min_count=2 retains 7487 unique words (50% of original 14750, drops 7263)\n",
      "2018-03-03 18:47:15,449 : INFO : min_count=2 leaves 139242 word corpus (95% of original 146505, drops 7263)\n",
      "2018-03-03 18:47:15,514 : INFO : deleting the raw counts dictionary of 14750 items\n",
      "2018-03-03 18:47:15,519 : INFO : sample=0.001 downsamples 38 most-common words\n",
      "2018-03-03 18:47:15,520 : INFO : downsampling leaves estimated 101633 word corpus (73.0% of prior 139242)\n",
      "2018-03-03 18:47:15,574 : INFO : estimated required memory for 7487 words and 100 dimensions: 9733100 bytes\n",
      "2018-03-03 18:47:15,579 : INFO : resetting layer weights\n",
      "2018-03-03 18:47:15,745 : INFO : training model with 3 workers on 7487 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-03-03 18:47:16,852 : INFO : EPOCH 1 - PROGRESS: at 16.43% examples, 12450 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:17,864 : INFO : EPOCH 1 - PROGRESS: at 36.60% examples, 15908 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:19,031 : INFO : EPOCH 1 - PROGRESS: at 67.72% examples, 20477 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:20,139 : INFO : EPOCH 1 - PROGRESS: at 98.27% examples, 22891 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:20,148 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:47:20,152 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:47:20,154 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:47:20,157 : INFO : EPOCH - 1 : training on 146505 raw words (101482 effective words) took 4.4s, 23134 effective words/s\n",
      "2018-03-03 18:47:21,257 : INFO : EPOCH 2 - PROGRESS: at 36.60% examples, 30580 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:22,320 : INFO : EPOCH 2 - PROGRESS: at 67.72% examples, 31047 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:23,322 : INFO : EPOCH 2 - PROGRESS: at 98.27% examples, 31759 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:23,342 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:47:23,343 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:47:23,346 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:47:23,347 : INFO : EPOCH - 2 : training on 146505 raw words (101650 effective words) took 3.2s, 31965 effective words/s\n",
      "2018-03-03 18:47:24,378 : INFO : EPOCH 3 - PROGRESS: at 29.97% examples, 25967 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:25,545 : INFO : EPOCH 3 - PROGRESS: at 67.72% examples, 30465 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:26,637 : INFO : EPOCH 3 - PROGRESS: at 98.27% examples, 30519 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:26,661 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:47:26,662 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:47:26,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:47:26,667 : INFO : EPOCH - 3 : training on 146505 raw words (101718 effective words) took 3.3s, 30677 effective words/s\n",
      "2018-03-03 18:47:27,746 : INFO : EPOCH 4 - PROGRESS: at 36.60% examples, 31044 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:28,927 : INFO : EPOCH 4 - PROGRESS: at 73.49% examples, 32669 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:29,702 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:47:29,703 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:47:29,707 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:47:29,709 : INFO : EPOCH - 4 : training on 146505 raw words (101802 effective words) took 3.0s, 33506 effective words/s\n",
      "2018-03-03 18:47:30,840 : INFO : EPOCH 5 - PROGRESS: at 36.60% examples, 29698 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:32,011 : INFO : EPOCH 5 - PROGRESS: at 67.72% examples, 29140 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:32,961 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:47:32,963 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:47:32,966 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:47:32,968 : INFO : EPOCH - 5 : training on 146505 raw words (101623 effective words) took 3.3s, 31259 effective words/s\n",
      "2018-03-03 18:47:34,049 : INFO : EPOCH 6 - PROGRESS: at 36.60% examples, 31082 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:35,062 : INFO : EPOCH 6 - PROGRESS: at 67.72% examples, 32036 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:36,160 : INFO : EPOCH 6 - PROGRESS: at 98.27% examples, 31468 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:36,191 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:47:36,192 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:47:36,198 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:47:36,202 : INFO : EPOCH - 6 : training on 146505 raw words (101555 effective words) took 3.2s, 31506 effective words/s\n",
      "2018-03-03 18:47:37,404 : INFO : EPOCH 7 - PROGRESS: at 36.60% examples, 28247 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:38,550 : INFO : EPOCH 7 - PROGRESS: at 67.72% examples, 28699 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:39,651 : INFO : EPOCH 7 - PROGRESS: at 92.80% examples, 27221 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:39,896 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:47:39,897 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:47:39,903 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:47:39,905 : INFO : EPOCH - 7 : training on 146505 raw words (101604 effective words) took 3.7s, 27609 effective words/s\n",
      "2018-03-03 18:47:41,034 : INFO : EPOCH 8 - PROGRESS: at 29.97% examples, 23723 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:42,202 : INFO : EPOCH 8 - PROGRESS: at 63.69% examples, 26227 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:43,242 : INFO : EPOCH 8 - PROGRESS: at 88.18% examples, 26014 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:43,851 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:47:43,852 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:47:43,856 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:47:43,857 : INFO : EPOCH - 8 : training on 146505 raw words (101703 effective words) took 3.9s, 25789 effective words/s\n",
      "2018-03-03 18:47:44,939 : INFO : EPOCH 9 - PROGRESS: at 29.97% examples, 24809 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:46,073 : INFO : EPOCH 9 - PROGRESS: at 57.06% examples, 24308 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:47,171 : INFO : EPOCH 9 - PROGRESS: at 88.18% examples, 26158 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:47,524 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:47:47,525 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:47:47,528 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:47:47,529 : INFO : EPOCH - 9 : training on 146505 raw words (101610 effective words) took 3.7s, 27711 effective words/s\n",
      "2018-03-03 18:47:48,604 : INFO : EPOCH 10 - PROGRESS: at 36.60% examples, 31132 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:49,611 : INFO : EPOCH 10 - PROGRESS: at 67.72% examples, 32173 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:50,722 : INFO : EPOCH 10 - PROGRESS: at 98.27% examples, 31405 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:50,786 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:47:50,789 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-03 18:47:50,796 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:47:50,802 : INFO : EPOCH - 10 : training on 146505 raw words (101668 effective words) took 3.3s, 31088 effective words/s\n",
      "2018-03-03 18:47:51,848 : INFO : EPOCH 11 - PROGRESS: at 29.97% examples, 25932 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:52,886 : INFO : EPOCH 11 - PROGRESS: at 63.69% examples, 29074 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:54,042 : INFO : EPOCH 11 - PROGRESS: at 98.27% examples, 31088 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:54,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:47:54,067 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:47:54,069 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:47:54,070 : INFO : EPOCH - 11 : training on 146505 raw words (101614 effective words) took 3.3s, 31260 effective words/s\n",
      "2018-03-03 18:47:55,101 : INFO : EPOCH 12 - PROGRESS: at 36.60% examples, 32845 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:56,250 : INFO : EPOCH 12 - PROGRESS: at 67.72% examples, 30793 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:57,230 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:47:57,231 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:47:57,236 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:47:57,239 : INFO : EPOCH - 12 : training on 146505 raw words (101596 effective words) took 3.2s, 32207 effective words/s\n",
      "2018-03-03 18:47:58,306 : INFO : EPOCH 13 - PROGRESS: at 36.60% examples, 31335 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:47:59,420 : INFO : EPOCH 13 - PROGRESS: at 73.49% examples, 33791 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:00,250 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:00,251 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:00,255 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:00,257 : INFO : EPOCH - 13 : training on 146505 raw words (101574 effective words) took 3.0s, 33696 effective words/s\n",
      "2018-03-03 18:48:01,457 : INFO : EPOCH 14 - PROGRESS: at 43.52% examples, 33742 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:02,658 : INFO : EPOCH 14 - PROGRESS: at 73.49% examples, 30728 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:03,578 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:03,579 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:03,583 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:03,584 : INFO : EPOCH - 14 : training on 146505 raw words (101579 effective words) took 3.3s, 30585 effective words/s\n",
      "2018-03-03 18:48:04,698 : INFO : EPOCH 15 - PROGRESS: at 29.97% examples, 24130 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:05,735 : INFO : EPOCH 15 - PROGRESS: at 63.69% examples, 28049 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:06,812 : INFO : EPOCH 15 - PROGRESS: at 92.80% examples, 28976 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:07,013 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:07,014 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:07,018 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:07,019 : INFO : EPOCH - 15 : training on 146505 raw words (101617 effective words) took 3.4s, 29659 effective words/s\n",
      "2018-03-03 18:48:08,045 : INFO : EPOCH 16 - PROGRESS: at 36.60% examples, 32666 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:09,146 : INFO : EPOCH 16 - PROGRESS: at 67.72% examples, 31468 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:10,180 : INFO : EPOCH 16 - PROGRESS: at 98.27% examples, 31704 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:10,208 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:10,209 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:10,213 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:10,214 : INFO : EPOCH - 16 : training on 146505 raw words (101497 effective words) took 3.2s, 31822 effective words/s\n",
      "2018-03-03 18:48:11,222 : INFO : EPOCH 17 - PROGRESS: at 29.97% examples, 26621 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:12,392 : INFO : EPOCH 17 - PROGRESS: at 63.69% examples, 27655 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:13,540 : INFO : EPOCH 17 - PROGRESS: at 92.80% examples, 28100 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:13,729 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:13,730 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:13,734 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:13,735 : INFO : EPOCH - 17 : training on 146505 raw words (101568 effective words) took 3.5s, 28921 effective words/s\n",
      "2018-03-03 18:48:14,755 : INFO : EPOCH 18 - PROGRESS: at 29.97% examples, 26370 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:15,766 : INFO : EPOCH 18 - PROGRESS: at 57.06% examples, 26556 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:16,831 : INFO : EPOCH 18 - PROGRESS: at 88.18% examples, 28022 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:17,260 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:17,261 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:17,264 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:17,265 : INFO : EPOCH - 18 : training on 146505 raw words (101679 effective words) took 3.5s, 28854 effective words/s\n",
      "2018-03-03 18:48:18,412 : INFO : EPOCH 19 - PROGRESS: at 36.60% examples, 29183 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:19,520 : INFO : EPOCH 19 - PROGRESS: at 63.69% examples, 26702 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:20,662 : INFO : EPOCH 19 - PROGRESS: at 92.80% examples, 27509 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:20,890 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:20,892 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:20,896 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:20,898 : INFO : EPOCH - 19 : training on 146505 raw words (101538 effective words) took 3.6s, 28017 effective words/s\n",
      "2018-03-03 18:48:21,925 : INFO : EPOCH 20 - PROGRESS: at 36.60% examples, 32730 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:23,091 : INFO : EPOCH 20 - PROGRESS: at 73.49% examples, 33702 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:23,955 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:23,956 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:23,959 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:23,961 : INFO : EPOCH - 20 : training on 146505 raw words (101634 effective words) took 3.1s, 33257 effective words/s\n",
      "2018-03-03 18:48:24,992 : INFO : EPOCH 21 - PROGRESS: at 36.60% examples, 32751 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:26,151 : INFO : EPOCH 21 - PROGRESS: at 73.49% examples, 33770 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:26,917 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:26,918 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:26,922 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:26,925 : INFO : EPOCH - 21 : training on 146505 raw words (101688 effective words) took 3.0s, 34409 effective words/s\n",
      "2018-03-03 18:48:28,069 : INFO : EPOCH 22 - PROGRESS: at 29.97% examples, 23385 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:29,304 : INFO : EPOCH 22 - PROGRESS: at 63.69% examples, 25318 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:30,310 : INFO : EPOCH 22 - PROGRESS: at 88.18% examples, 25590 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-03 18:48:30,675 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:30,675 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:30,679 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:30,680 : INFO : EPOCH - 22 : training on 146505 raw words (101592 effective words) took 3.7s, 27099 effective words/s\n",
      "2018-03-03 18:48:31,763 : INFO : EPOCH 23 - PROGRESS: at 36.60% examples, 30969 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:32,842 : INFO : EPOCH 23 - PROGRESS: at 67.72% examples, 30968 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:33,918 : INFO : EPOCH 23 - PROGRESS: at 92.80% examples, 28863 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:34,115 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:34,117 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:34,120 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:34,122 : INFO : EPOCH - 23 : training on 146505 raw words (101582 effective words) took 3.4s, 29578 effective words/s\n",
      "2018-03-03 18:48:35,136 : INFO : EPOCH 24 - PROGRESS: at 29.97% examples, 26474 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:36,218 : INFO : EPOCH 24 - PROGRESS: at 63.69% examples, 28785 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:37,364 : INFO : EPOCH 24 - PROGRESS: at 98.27% examples, 30987 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:37,386 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:37,387 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:37,391 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:37,392 : INFO : EPOCH - 24 : training on 146505 raw words (101728 effective words) took 3.3s, 31174 effective words/s\n",
      "2018-03-03 18:48:38,491 : INFO : EPOCH 25 - PROGRESS: at 36.60% examples, 30641 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:39,572 : INFO : EPOCH 25 - PROGRESS: at 67.72% examples, 30785 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:40,546 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:40,547 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:40,551 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:40,552 : INFO : EPOCH - 25 : training on 146505 raw words (101703 effective words) took 3.2s, 32260 effective words/s\n",
      "2018-03-03 18:48:41,668 : INFO : EPOCH 26 - PROGRESS: at 36.60% examples, 30063 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:42,843 : INFO : EPOCH 26 - PROGRESS: at 67.72% examples, 29294 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:43,836 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:43,837 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:43,841 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:43,843 : INFO : EPOCH - 26 : training on 146505 raw words (101794 effective words) took 3.3s, 30987 effective words/s\n",
      "2018-03-03 18:48:44,973 : INFO : EPOCH 27 - PROGRESS: at 36.60% examples, 29618 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:46,152 : INFO : EPOCH 27 - PROGRESS: at 67.72% examples, 28936 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:47,232 : INFO : EPOCH 27 - PROGRESS: at 98.27% examples, 29573 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:47,257 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:47,258 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:47,262 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:47,264 : INFO : EPOCH - 27 : training on 146505 raw words (101547 effective words) took 3.4s, 29720 effective words/s\n",
      "2018-03-03 18:48:48,269 : INFO : EPOCH 28 - PROGRESS: at 36.60% examples, 33390 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:49,427 : INFO : EPOCH 28 - PROGRESS: at 73.49% examples, 34072 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:50,209 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:50,210 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:50,214 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:50,217 : INFO : EPOCH - 28 : training on 146505 raw words (101543 effective words) took 2.9s, 34422 effective words/s\n",
      "2018-03-03 18:48:51,309 : INFO : EPOCH 29 - PROGRESS: at 36.60% examples, 30733 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:52,480 : INFO : EPOCH 29 - PROGRESS: at 73.49% examples, 32592 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:53,223 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:53,224 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:53,226 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:53,227 : INFO : EPOCH - 29 : training on 146505 raw words (101623 effective words) took 3.0s, 33815 effective words/s\n",
      "2018-03-03 18:48:54,286 : INFO : EPOCH 30 - PROGRESS: at 36.60% examples, 31791 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:55,523 : INFO : EPOCH 30 - PROGRESS: at 73.49% examples, 32186 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:56,334 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:56,335 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:56,339 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:56,341 : INFO : EPOCH - 30 : training on 146505 raw words (101829 effective words) took 3.1s, 32753 effective words/s\n",
      "2018-03-03 18:48:57,373 : INFO : EPOCH 31 - PROGRESS: at 36.60% examples, 32384 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:58,589 : INFO : EPOCH 31 - PROGRESS: at 73.49% examples, 32764 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:48:59,387 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:48:59,388 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:48:59,391 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:48:59,392 : INFO : EPOCH - 31 : training on 146505 raw words (101565 effective words) took 3.0s, 33329 effective words/s\n",
      "2018-03-03 18:49:00,491 : INFO : EPOCH 32 - PROGRESS: at 29.97% examples, 24353 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:01,539 : INFO : EPOCH 32 - PROGRESS: at 63.69% examples, 28056 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:02,636 : INFO : EPOCH 32 - PROGRESS: at 98.27% examples, 30942 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:02,654 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:02,656 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:02,662 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:02,663 : INFO : EPOCH - 32 : training on 146505 raw words (101690 effective words) took 3.3s, 31135 effective words/s\n",
      "2018-03-03 18:49:03,821 : INFO : EPOCH 33 - PROGRESS: at 36.60% examples, 28869 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:05,076 : INFO : EPOCH 33 - PROGRESS: at 67.72% examples, 27733 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:06,128 : INFO : EPOCH 33 - PROGRESS: at 92.80% examples, 26931 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:06,411 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:06,411 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:06,414 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:06,416 : INFO : EPOCH - 33 : training on 146505 raw words (101556 effective words) took 3.7s, 27095 effective words/s\n",
      "2018-03-03 18:49:07,546 : INFO : EPOCH 34 - PROGRESS: at 29.97% examples, 23682 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:08,594 : INFO : EPOCH 34 - PROGRESS: at 63.69% examples, 27680 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:09,645 : INFO : EPOCH 34 - PROGRESS: at 82.13% examples, 24914 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-03 18:49:10,469 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:10,471 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:10,476 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:10,477 : INFO : EPOCH - 34 : training on 146505 raw words (101641 effective words) took 4.1s, 25057 effective words/s\n",
      "2018-03-03 18:49:11,567 : INFO : EPOCH 35 - PROGRESS: at 29.97% examples, 24603 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:12,640 : INFO : EPOCH 35 - PROGRESS: at 57.06% examples, 24851 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:13,733 : INFO : EPOCH 35 - PROGRESS: at 82.13% examples, 24689 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:14,541 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:14,542 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:14,551 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:14,553 : INFO : EPOCH - 35 : training on 146505 raw words (101474 effective words) took 4.1s, 24934 effective words/s\n",
      "2018-03-03 18:49:15,713 : INFO : EPOCH 36 - PROGRESS: at 29.97% examples, 23150 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:16,787 : INFO : EPOCH 36 - PROGRESS: at 57.06% examples, 24159 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:18,070 : INFO : EPOCH 36 - PROGRESS: at 82.13% examples, 22915 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:18,794 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:18,796 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:18,799 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:18,804 : INFO : EPOCH - 36 : training on 146505 raw words (101712 effective words) took 4.2s, 23960 effective words/s\n",
      "2018-03-03 18:49:19,995 : INFO : EPOCH 37 - PROGRESS: at 36.60% examples, 28320 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:21,193 : INFO : EPOCH 37 - PROGRESS: at 73.49% examples, 30947 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:21,986 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:21,987 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:21,990 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:21,991 : INFO : EPOCH - 37 : training on 146505 raw words (101482 effective words) took 3.2s, 31977 effective words/s\n",
      "2018-03-03 18:49:23,189 : INFO : EPOCH 38 - PROGRESS: at 43.52% examples, 33790 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:24,333 : INFO : EPOCH 38 - PROGRESS: at 82.13% examples, 34374 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:24,897 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:24,899 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:24,902 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:24,904 : INFO : EPOCH - 38 : training on 146505 raw words (101660 effective words) took 2.9s, 34948 effective words/s\n",
      "2018-03-03 18:49:26,017 : INFO : EPOCH 39 - PROGRESS: at 36.60% examples, 30163 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:27,173 : INFO : EPOCH 39 - PROGRESS: at 73.49% examples, 32548 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:27,958 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:27,960 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:27,962 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:27,962 : INFO : EPOCH - 39 : training on 146505 raw words (101734 effective words) took 3.1s, 33300 effective words/s\n",
      "2018-03-03 18:49:29,061 : INFO : EPOCH 40 - PROGRESS: at 36.60% examples, 30618 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:30,134 : INFO : EPOCH 40 - PROGRESS: at 67.72% examples, 30962 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:31,073 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:31,074 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:31,077 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:31,080 : INFO : EPOCH - 40 : training on 146505 raw words (101760 effective words) took 3.1s, 32735 effective words/s\n",
      "2018-03-03 18:49:32,276 : INFO : EPOCH 41 - PROGRESS: at 43.52% examples, 33760 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:33,447 : INFO : EPOCH 41 - PROGRESS: at 82.13% examples, 33968 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:34,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:34,064 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:34,067 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:34,069 : INFO : EPOCH - 41 : training on 146505 raw words (101612 effective words) took 3.0s, 34033 effective words/s\n",
      "2018-03-03 18:49:35,253 : INFO : EPOCH 42 - PROGRESS: at 36.60% examples, 28289 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:36,267 : INFO : EPOCH 42 - PROGRESS: at 63.69% examples, 27394 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:37,363 : INFO : EPOCH 42 - PROGRESS: at 92.80% examples, 28376 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:37,564 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:37,565 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:37,570 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:37,572 : INFO : EPOCH - 42 : training on 146505 raw words (101700 effective words) took 3.5s, 29077 effective words/s\n",
      "2018-03-03 18:49:38,722 : INFO : EPOCH 43 - PROGRESS: at 36.60% examples, 29170 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:39,837 : INFO : EPOCH 43 - PROGRESS: at 67.72% examples, 29572 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:40,856 : INFO : EPOCH 43 - PROGRESS: at 98.27% examples, 30557 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:40,883 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:40,884 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:40,887 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:40,891 : INFO : EPOCH - 43 : training on 146505 raw words (101641 effective words) took 3.3s, 30674 effective words/s\n",
      "2018-03-03 18:49:42,087 : INFO : EPOCH 44 - PROGRESS: at 36.60% examples, 27992 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:43,143 : INFO : EPOCH 44 - PROGRESS: at 67.72% examples, 29757 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:44,340 : INFO : EPOCH 44 - PROGRESS: at 92.80% examples, 27101 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:44,563 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:44,564 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:44,573 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:44,582 : INFO : EPOCH - 44 : training on 146505 raw words (101667 effective words) took 3.7s, 27585 effective words/s\n",
      "2018-03-03 18:49:45,756 : INFO : EPOCH 45 - PROGRESS: at 36.60% examples, 28688 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:46,951 : INFO : EPOCH 45 - PROGRESS: at 67.72% examples, 28334 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:47,952 : INFO : EPOCH 45 - PROGRESS: at 98.27% examples, 29802 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:47,982 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:47,983 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:47,988 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:47,989 : INFO : EPOCH - 45 : training on 146505 raw words (101622 effective words) took 3.4s, 29902 effective words/s\n",
      "2018-03-03 18:49:49,085 : INFO : EPOCH 46 - PROGRESS: at 36.60% examples, 30646 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:50,245 : INFO : EPOCH 46 - PROGRESS: at 73.49% examples, 32736 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-03 18:49:50,981 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:50,982 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:50,986 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:50,987 : INFO : EPOCH - 46 : training on 146505 raw words (101671 effective words) took 3.0s, 33984 effective words/s\n",
      "2018-03-03 18:49:52,254 : INFO : EPOCH 47 - PROGRESS: at 43.52% examples, 31962 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:53,433 : INFO : EPOCH 47 - PROGRESS: at 73.49% examples, 30220 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:54,248 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:54,249 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:54,252 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:54,253 : INFO : EPOCH - 47 : training on 146505 raw words (101798 effective words) took 3.3s, 31218 effective words/s\n",
      "2018-03-03 18:49:55,354 : INFO : EPOCH 48 - PROGRESS: at 36.60% examples, 30536 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:56,367 : INFO : EPOCH 48 - PROGRESS: at 67.72% examples, 31716 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:57,455 : INFO : EPOCH 48 - PROGRESS: at 98.27% examples, 31365 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:57,473 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:49:57,474 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:49:57,477 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:49:57,485 : INFO : EPOCH - 48 : training on 146505 raw words (101697 effective words) took 3.2s, 31527 effective words/s\n",
      "2018-03-03 18:49:58,575 : INFO : EPOCH 49 - PROGRESS: at 36.60% examples, 30772 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:49:59,857 : INFO : EPOCH 49 - PROGRESS: at 67.72% examples, 28181 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:00,911 : INFO : EPOCH 49 - PROGRESS: at 92.80% examples, 27213 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:01,182 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:01,183 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:01,186 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:01,189 : INFO : EPOCH - 49 : training on 146505 raw words (101429 effective words) took 3.7s, 27418 effective words/s\n",
      "2018-03-03 18:50:02,381 : INFO : EPOCH 50 - PROGRESS: at 29.97% examples, 22494 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:03,503 : INFO : EPOCH 50 - PROGRESS: at 63.69% examples, 26019 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:04,513 : INFO : EPOCH 50 - PROGRESS: at 88.18% examples, 26050 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:04,908 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:04,909 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:04,915 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:04,919 : INFO : EPOCH - 50 : training on 146505 raw words (101598 effective words) took 3.7s, 27262 effective words/s\n",
      "2018-03-03 18:50:06,022 : INFO : EPOCH 51 - PROGRESS: at 29.97% examples, 24379 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:07,274 : INFO : EPOCH 51 - PROGRESS: at 57.06% examples, 22873 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:08,536 : INFO : EPOCH 51 - PROGRESS: at 88.18% examples, 23977 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:09,028 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:09,029 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:09,033 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:09,036 : INFO : EPOCH - 51 : training on 146505 raw words (101654 effective words) took 4.1s, 24746 effective words/s\n",
      "2018-03-03 18:50:10,080 : INFO : EPOCH 52 - PROGRESS: at 29.97% examples, 25760 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:11,208 : INFO : EPOCH 52 - PROGRESS: at 57.06% examples, 24818 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:12,396 : INFO : EPOCH 52 - PROGRESS: at 92.80% examples, 27870 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:12,622 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:12,623 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:12,628 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:12,630 : INFO : EPOCH - 52 : training on 146505 raw words (101768 effective words) took 3.6s, 28380 effective words/s\n",
      "2018-03-03 18:50:13,874 : INFO : EPOCH 53 - PROGRESS: at 36.60% examples, 26952 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:15,065 : INFO : EPOCH 53 - PROGRESS: at 67.72% examples, 27543 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:16,072 : INFO : EPOCH 53 - PROGRESS: at 98.27% examples, 29183 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:16,104 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:16,106 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:16,108 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:16,110 : INFO : EPOCH - 53 : training on 146505 raw words (101678 effective words) took 3.5s, 29285 effective words/s\n",
      "2018-03-03 18:50:17,327 : INFO : EPOCH 54 - PROGRESS: at 36.60% examples, 27419 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:18,425 : INFO : EPOCH 54 - PROGRESS: at 67.72% examples, 28898 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:19,512 : INFO : EPOCH 54 - PROGRESS: at 98.27% examples, 29497 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:19,531 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:19,532 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:19,536 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:19,537 : INFO : EPOCH - 54 : training on 146505 raw words (101696 effective words) took 3.4s, 29708 effective words/s\n",
      "2018-03-03 18:50:20,619 : INFO : EPOCH 55 - PROGRESS: at 36.60% examples, 30958 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:21,624 : INFO : EPOCH 55 - PROGRESS: at 67.72% examples, 32057 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:22,594 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:22,595 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:22,599 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:22,601 : INFO : EPOCH - 55 : training on 146505 raw words (101619 effective words) took 3.1s, 33208 effective words/s\n",
      "2018-03-03 18:50:23,730 : INFO : EPOCH 56 - PROGRESS: at 36.60% examples, 29664 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:24,923 : INFO : EPOCH 56 - PROGRESS: at 73.49% examples, 31733 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:25,683 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:25,684 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:25,687 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:25,690 : INFO : EPOCH - 56 : training on 146505 raw words (101666 effective words) took 3.1s, 32959 effective words/s\n",
      "2018-03-03 18:50:26,722 : INFO : EPOCH 57 - PROGRESS: at 36.60% examples, 32474 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:27,816 : INFO : EPOCH 57 - PROGRESS: at 67.72% examples, 31483 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:28,798 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:28,799 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:28,803 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:28,806 : INFO : EPOCH - 57 : training on 146505 raw words (101587 effective words) took 3.1s, 32669 effective words/s\n",
      "2018-03-03 18:50:29,822 : INFO : EPOCH 58 - PROGRESS: at 36.60% examples, 32969 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-03 18:50:30,897 : INFO : EPOCH 58 - PROGRESS: at 67.72% examples, 31994 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:31,896 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:31,897 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:31,900 : INFO : EPOCH 58 - PROGRESS: at 100.00% examples, 32874 words/s, in_qsize 0, out_qsize 1\n",
      "2018-03-03 18:50:31,901 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:31,903 : INFO : EPOCH - 58 : training on 146505 raw words (101607 effective words) took 3.1s, 32838 effective words/s\n",
      "2018-03-03 18:50:33,010 : INFO : EPOCH 59 - PROGRESS: at 36.60% examples, 30378 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:34,068 : INFO : EPOCH 59 - PROGRESS: at 67.72% examples, 30988 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:35,200 : INFO : EPOCH 59 - PROGRESS: at 98.27% examples, 30459 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:35,219 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:35,220 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:35,224 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:35,225 : INFO : EPOCH - 59 : training on 146505 raw words (101665 effective words) took 3.3s, 30673 effective words/s\n",
      "2018-03-03 18:50:36,360 : INFO : EPOCH 60 - PROGRESS: at 36.60% examples, 29682 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:37,514 : INFO : EPOCH 60 - PROGRESS: at 73.49% examples, 32367 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:38,259 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:38,260 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:38,264 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:38,265 : INFO : EPOCH - 60 : training on 146505 raw words (101949 effective words) took 3.0s, 33629 effective words/s\n",
      "2018-03-03 18:50:39,297 : INFO : EPOCH 61 - PROGRESS: at 36.60% examples, 32547 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:40,547 : INFO : EPOCH 61 - PROGRESS: at 73.49% examples, 32363 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:41,308 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:41,309 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:41,312 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:41,313 : INFO : EPOCH - 61 : training on 146505 raw words (101719 effective words) took 3.0s, 33418 effective words/s\n",
      "2018-03-03 18:50:42,529 : INFO : EPOCH 62 - PROGRESS: at 43.52% examples, 33213 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:43,688 : INFO : EPOCH 62 - PROGRESS: at 82.13% examples, 33924 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:44,219 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:44,221 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:44,224 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:44,228 : INFO : EPOCH - 62 : training on 146505 raw words (101682 effective words) took 2.9s, 34923 effective words/s\n",
      "2018-03-03 18:50:45,330 : INFO : EPOCH 63 - PROGRESS: at 36.60% examples, 30645 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:46,473 : INFO : EPOCH 63 - PROGRESS: at 73.49% examples, 32958 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:47,214 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:47,215 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:47,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:47,221 : INFO : EPOCH - 63 : training on 146505 raw words (101609 effective words) took 3.0s, 34065 effective words/s\n",
      "2018-03-03 18:50:48,420 : INFO : EPOCH 64 - PROGRESS: at 43.52% examples, 33759 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:49,619 : INFO : EPOCH 64 - PROGRESS: at 82.13% examples, 33636 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:50,161 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:50,163 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:50,167 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:50,174 : INFO : EPOCH - 64 : training on 146505 raw words (101747 effective words) took 2.9s, 34512 effective words/s\n",
      "2018-03-03 18:50:51,366 : INFO : EPOCH 65 - PROGRESS: at 43.52% examples, 33887 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:52,505 : INFO : EPOCH 65 - PROGRESS: at 82.13% examples, 34543 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:53,032 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:53,033 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:53,038 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:53,039 : INFO : EPOCH - 65 : training on 146505 raw words (101610 effective words) took 2.9s, 35540 effective words/s\n",
      "2018-03-03 18:50:54,109 : INFO : EPOCH 66 - PROGRESS: at 36.60% examples, 31341 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:55,307 : INFO : EPOCH 66 - PROGRESS: at 73.49% examples, 32523 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:56,068 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:56,069 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:56,072 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:56,074 : INFO : EPOCH - 66 : training on 146505 raw words (101676 effective words) took 3.0s, 33536 effective words/s\n",
      "2018-03-03 18:50:57,161 : INFO : EPOCH 67 - PROGRESS: at 36.60% examples, 30867 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:58,301 : INFO : EPOCH 67 - PROGRESS: at 73.49% examples, 33150 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:50:59,032 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:50:59,033 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:50:59,036 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:50:59,038 : INFO : EPOCH - 67 : training on 146505 raw words (101649 effective words) took 3.0s, 34370 effective words/s\n",
      "2018-03-03 18:51:00,255 : INFO : EPOCH 68 - PROGRESS: at 43.52% examples, 33152 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:01,335 : INFO : EPOCH 68 - PROGRESS: at 73.49% examples, 32087 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:02,102 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:02,103 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:02,107 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:02,110 : INFO : EPOCH - 68 : training on 146505 raw words (101557 effective words) took 3.1s, 33102 effective words/s\n",
      "2018-03-03 18:51:03,131 : INFO : EPOCH 69 - PROGRESS: at 36.60% examples, 32847 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:04,157 : INFO : EPOCH 69 - PROGRESS: at 67.72% examples, 32718 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:05,166 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:05,167 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:05,171 : INFO : EPOCH 69 - PROGRESS: at 100.00% examples, 33294 words/s, in_qsize 0, out_qsize 1\n",
      "2018-03-03 18:51:05,173 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:05,174 : INFO : EPOCH - 69 : training on 146505 raw words (101772 effective words) took 3.1s, 33260 effective words/s\n",
      "2018-03-03 18:51:06,224 : INFO : EPOCH 70 - PROGRESS: at 29.97% examples, 25529 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:07,421 : INFO : EPOCH 70 - PROGRESS: at 67.72% examples, 29762 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:08,365 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:08,366 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-03 18:51:08,368 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:08,370 : INFO : EPOCH - 70 : training on 146505 raw words (101539 effective words) took 3.2s, 31827 effective words/s\n",
      "2018-03-03 18:51:09,440 : INFO : EPOCH 71 - PROGRESS: at 36.60% examples, 31378 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:10,566 : INFO : EPOCH 71 - PROGRESS: at 67.72% examples, 30552 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:11,494 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:11,495 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:11,500 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:11,505 : INFO : EPOCH - 71 : training on 146505 raw words (101856 effective words) took 3.1s, 32548 effective words/s\n",
      "2018-03-03 18:51:12,588 : INFO : EPOCH 72 - PROGRESS: at 36.60% examples, 30855 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:13,672 : INFO : EPOCH 72 - PROGRESS: at 67.72% examples, 30843 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:14,701 : INFO : EPOCH 72 - PROGRESS: at 98.27% examples, 31369 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:14,726 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:14,727 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:14,731 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:14,732 : INFO : EPOCH - 72 : training on 146505 raw words (101615 effective words) took 3.2s, 31530 effective words/s\n",
      "2018-03-03 18:51:15,911 : INFO : EPOCH 73 - PROGRESS: at 36.60% examples, 28479 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:17,115 : INFO : EPOCH 73 - PROGRESS: at 73.49% examples, 30991 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:17,849 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:17,851 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:17,854 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:17,857 : INFO : EPOCH - 73 : training on 146505 raw words (101553 effective words) took 3.1s, 32593 effective words/s\n",
      "2018-03-03 18:51:19,025 : INFO : EPOCH 74 - PROGRESS: at 36.60% examples, 28638 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:20,069 : INFO : EPOCH 74 - PROGRESS: at 67.72% examples, 30254 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:21,076 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:21,078 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:21,081 : INFO : EPOCH 74 - PROGRESS: at 100.00% examples, 31545 words/s, in_qsize 0, out_qsize 1\n",
      "2018-03-03 18:51:21,082 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:21,083 : INFO : EPOCH - 74 : training on 146505 raw words (101580 effective words) took 3.2s, 31524 effective words/s\n",
      "2018-03-03 18:51:22,148 : INFO : EPOCH 75 - PROGRESS: at 36.60% examples, 31453 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:23,451 : INFO : EPOCH 75 - PROGRESS: at 73.49% examples, 31149 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:24,224 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:24,226 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:24,232 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:24,234 : INFO : EPOCH - 75 : training on 146505 raw words (101568 effective words) took 3.1s, 32280 effective words/s\n",
      "2018-03-03 18:51:25,273 : INFO : EPOCH 76 - PROGRESS: at 36.60% examples, 32400 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:26,456 : INFO : EPOCH 76 - PROGRESS: at 73.49% examples, 33247 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:27,209 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:27,210 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:27,213 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:27,215 : INFO : EPOCH - 76 : training on 146505 raw words (101571 effective words) took 3.0s, 34169 effective words/s\n",
      "2018-03-03 18:51:28,324 : INFO : EPOCH 77 - PROGRESS: at 36.60% examples, 30312 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:29,359 : INFO : EPOCH 77 - PROGRESS: at 67.72% examples, 31279 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:30,304 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:30,305 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:30,309 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:30,311 : INFO : EPOCH - 77 : training on 146505 raw words (101756 effective words) took 3.1s, 32915 effective words/s\n",
      "2018-03-03 18:51:31,495 : INFO : EPOCH 78 - PROGRESS: at 43.52% examples, 34220 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:32,515 : INFO : EPOCH 78 - PROGRESS: at 73.49% examples, 33549 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:33,271 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:33,272 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:33,276 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:33,278 : INFO : EPOCH - 78 : training on 146505 raw words (101748 effective words) took 3.0s, 34379 effective words/s\n",
      "2018-03-03 18:51:34,496 : INFO : EPOCH 79 - PROGRESS: at 43.52% examples, 33270 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:35,663 : INFO : EPOCH 79 - PROGRESS: at 82.13% examples, 33788 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:36,226 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:36,227 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:36,230 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:36,231 : INFO : EPOCH - 79 : training on 146505 raw words (101710 effective words) took 2.9s, 34529 effective words/s\n",
      "2018-03-03 18:51:37,293 : INFO : EPOCH 80 - PROGRESS: at 36.60% examples, 31645 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:38,445 : INFO : EPOCH 80 - PROGRESS: at 73.49% examples, 33420 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:39,185 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:39,186 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:39,188 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:39,189 : INFO : EPOCH - 80 : training on 146505 raw words (101774 effective words) took 3.0s, 34477 effective words/s\n",
      "2018-03-03 18:51:40,282 : INFO : EPOCH 81 - PROGRESS: at 36.60% examples, 30757 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:41,426 : INFO : EPOCH 81 - PROGRESS: at 73.49% examples, 33004 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:42,181 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:42,182 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:42,185 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:42,186 : INFO : EPOCH - 81 : training on 146505 raw words (101687 effective words) took 3.0s, 33991 effective words/s\n",
      "2018-03-03 18:51:43,214 : INFO : EPOCH 82 - PROGRESS: at 36.60% examples, 32538 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:44,421 : INFO : EPOCH 82 - PROGRESS: at 73.49% examples, 32949 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:45,174 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:45,175 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:45,178 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:45,180 : INFO : EPOCH - 82 : training on 146505 raw words (101555 effective words) took 3.0s, 33982 effective words/s\n",
      "2018-03-03 18:51:46,373 : INFO : EPOCH 83 - PROGRESS: at 43.52% examples, 33831 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:47,525 : INFO : EPOCH 83 - PROGRESS: at 82.13% examples, 34302 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-03 18:51:48,043 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:48,044 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:48,046 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:48,048 : INFO : EPOCH - 83 : training on 146505 raw words (101613 effective words) took 2.9s, 35466 effective words/s\n",
      "2018-03-03 18:51:49,116 : INFO : EPOCH 84 - PROGRESS: at 36.60% examples, 31409 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:50,229 : INFO : EPOCH 84 - PROGRESS: at 73.49% examples, 33830 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:50,956 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:50,957 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:50,961 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:50,962 : INFO : EPOCH - 84 : training on 146505 raw words (101677 effective words) took 2.9s, 34945 effective words/s\n",
      "2018-03-03 18:51:52,106 : INFO : EPOCH 85 - PROGRESS: at 43.52% examples, 35435 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:53,302 : INFO : EPOCH 85 - PROGRESS: at 82.13% examples, 34438 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:53,846 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:53,847 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:53,851 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:53,852 : INFO : EPOCH - 85 : training on 146505 raw words (101677 effective words) took 2.9s, 35257 effective words/s\n",
      "2018-03-03 18:51:55,047 : INFO : EPOCH 86 - PROGRESS: at 43.52% examples, 33758 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:56,185 : INFO : EPOCH 86 - PROGRESS: at 82.13% examples, 34472 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:56,727 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:56,729 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:56,732 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:56,733 : INFO : EPOCH - 86 : training on 146505 raw words (101487 effective words) took 2.9s, 35291 effective words/s\n",
      "2018-03-03 18:51:57,804 : INFO : EPOCH 87 - PROGRESS: at 36.60% examples, 31359 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:58,939 : INFO : EPOCH 87 - PROGRESS: at 73.49% examples, 33438 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:51:59,685 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:51:59,686 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:51:59,689 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:51:59,691 : INFO : EPOCH - 87 : training on 146505 raw words (101660 effective words) took 3.0s, 34418 effective words/s\n",
      "2018-03-03 18:52:00,736 : INFO : EPOCH 88 - PROGRESS: at 36.60% examples, 32066 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:01,873 : INFO : EPOCH 88 - PROGRESS: at 73.49% examples, 33831 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:02,626 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:52:02,628 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:52:02,631 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:52:02,632 : INFO : EPOCH - 88 : training on 146505 raw words (101728 effective words) took 2.9s, 34631 effective words/s\n",
      "2018-03-03 18:52:03,840 : INFO : EPOCH 89 - PROGRESS: at 43.52% examples, 33504 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:04,903 : INFO : EPOCH 89 - PROGRESS: at 73.49% examples, 32455 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:05,674 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:52:05,674 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:52:05,678 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:52:05,679 : INFO : EPOCH - 89 : training on 146505 raw words (101523 effective words) took 3.0s, 33393 effective words/s\n",
      "2018-03-03 18:52:06,885 : INFO : EPOCH 90 - PROGRESS: at 43.52% examples, 33504 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:08,008 : INFO : EPOCH 90 - PROGRESS: at 82.13% examples, 34563 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:08,533 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:52:08,534 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:52:08,538 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:52:08,540 : INFO : EPOCH - 90 : training on 146505 raw words (101748 effective words) took 2.9s, 35611 effective words/s\n",
      "2018-03-03 18:52:09,582 : INFO : EPOCH 91 - PROGRESS: at 36.60% examples, 32167 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:10,730 : INFO : EPOCH 91 - PROGRESS: at 73.49% examples, 33738 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:11,505 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:52:11,506 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:52:11,509 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:52:11,511 : INFO : EPOCH - 91 : training on 146505 raw words (101765 effective words) took 3.0s, 34311 effective words/s\n",
      "2018-03-03 18:52:12,710 : INFO : EPOCH 92 - PROGRESS: at 43.52% examples, 33693 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:13,725 : INFO : EPOCH 92 - PROGRESS: at 73.49% examples, 33343 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:14,645 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:52:14,647 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:52:14,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:52:14,650 : INFO : EPOCH - 92 : training on 146505 raw words (101624 effective words) took 3.1s, 32436 effective words/s\n",
      "2018-03-03 18:52:15,762 : INFO : EPOCH 93 - PROGRESS: at 36.60% examples, 30140 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:16,801 : INFO : EPOCH 93 - PROGRESS: at 67.72% examples, 31127 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:17,804 : INFO : EPOCH 93 - PROGRESS: at 98.27% examples, 31793 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:17,827 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:52:17,828 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:52:17,831 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:52:17,832 : INFO : EPOCH - 93 : training on 146505 raw words (101571 effective words) took 3.2s, 31968 effective words/s\n",
      "2018-03-03 18:52:18,906 : INFO : EPOCH 94 - PROGRESS: at 36.60% examples, 31128 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:19,974 : INFO : EPOCH 94 - PROGRESS: at 67.72% examples, 31219 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:21,019 : INFO : EPOCH 94 - PROGRESS: at 98.27% examples, 31445 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:21,048 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:52:21,049 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:52:21,054 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:52:21,057 : INFO : EPOCH - 94 : training on 146505 raw words (101546 effective words) took 3.2s, 31520 effective words/s\n",
      "2018-03-03 18:52:22,503 : INFO : EPOCH 95 - PROGRESS: at 36.60% examples, 23194 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:23,604 : INFO : EPOCH 95 - PROGRESS: at 67.72% examples, 26314 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:24,651 : INFO : EPOCH 95 - PROGRESS: at 92.80% examples, 26010 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:24,845 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:52:24,846 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:52:24,850 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-03 18:52:24,851 : INFO : EPOCH - 95 : training on 146505 raw words (101721 effective words) took 3.8s, 26850 effective words/s\n",
      "2018-03-03 18:52:25,982 : INFO : EPOCH 96 - PROGRESS: at 36.60% examples, 29604 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:27,054 : INFO : EPOCH 96 - PROGRESS: at 67.72% examples, 30344 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:28,150 : INFO : EPOCH 96 - PROGRESS: at 98.27% examples, 30352 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:28,175 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:52:28,178 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:52:28,182 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:52:28,186 : INFO : EPOCH - 96 : training on 146505 raw words (101461 effective words) took 3.3s, 30460 effective words/s\n",
      "2018-03-03 18:52:29,257 : INFO : EPOCH 97 - PROGRESS: at 29.97% examples, 24990 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:30,404 : INFO : EPOCH 97 - PROGRESS: at 63.69% examples, 27158 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:31,455 : INFO : EPOCH 97 - PROGRESS: at 92.80% examples, 28553 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:31,691 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:52:31,693 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:52:31,697 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:52:31,699 : INFO : EPOCH - 97 : training on 146505 raw words (101584 effective words) took 3.5s, 28955 effective words/s\n",
      "2018-03-03 18:52:32,838 : INFO : EPOCH 98 - PROGRESS: at 29.97% examples, 23576 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:33,902 : INFO : EPOCH 98 - PROGRESS: at 63.69% examples, 27314 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:34,955 : INFO : EPOCH 98 - PROGRESS: at 92.80% examples, 28663 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:35,166 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:52:35,167 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:52:35,170 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:52:35,171 : INFO : EPOCH - 98 : training on 146505 raw words (101457 effective words) took 3.5s, 29282 effective words/s\n",
      "2018-03-03 18:52:36,198 : INFO : EPOCH 99 - PROGRESS: at 29.97% examples, 26098 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:37,291 : INFO : EPOCH 99 - PROGRESS: at 63.69% examples, 28392 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:38,414 : INFO : EPOCH 99 - PROGRESS: at 92.80% examples, 28806 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:38,615 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:52:38,619 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:52:38,622 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:52:38,625 : INFO : EPOCH - 99 : training on 146505 raw words (101683 effective words) took 3.4s, 29478 effective words/s\n",
      "2018-03-03 18:52:39,732 : INFO : EPOCH 100 - PROGRESS: at 29.97% examples, 24264 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:40,930 : INFO : EPOCH 100 - PROGRESS: at 63.69% examples, 26146 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:41,957 : INFO : EPOCH 100 - PROGRESS: at 92.80% examples, 28032 words/s, in_qsize 0, out_qsize 0\n",
      "2018-03-03 18:52:42,157 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-03 18:52:42,159 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-03 18:52:42,163 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-03 18:52:42,166 : INFO : EPOCH - 100 : training on 146505 raw words (101438 effective words) took 3.5s, 28731 effective words/s\n",
      "2018-03-03 18:52:42,167 : INFO : training on a 14650500 raw words (10164034 effective words) took 326.4s, 31141 effective words/s\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "EMBED_SIZE=100\n",
    "embed_model = gensim.models.Word2Vec(edu_reader, size=EMBED_SIZE, min_count=2, window=5, iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result embedding shape: (7421, 100)\n",
      "Checking similar words:\n",
      "  money -> unusually (0.40), funds (0.38), transfers (0.38), reason (0.38)\n",
      "  bank -> company (0.41), portfolio (0.40), defendant (0.40), debt (0.39)\n",
      "  company -> bank (0.41), remaining (0.38), Manville (0.35), purchase (0.35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \n",
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "def check_similar(model):\n",
    "    pretrained_weights = model.wv.syn0\n",
    "    vocab_size, emdedding_size = pretrained_weights.shape\n",
    "    print('Result embedding shape:', pretrained_weights.shape)\n",
    "    print('Checking similar words:')\n",
    "    for word in ['money', 'bank', 'company']:\n",
    "        most_similar = ', '.join('%s (%.2f)' % (similar, dist) for similar, dist in model.most_similar(word)[:4])\n",
    "        print('  %s -> %s' % (word, most_similar))\n",
    "\n",
    "check_similar(embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence):\n",
    "        embeddings = [embed_model[word] for word in sentence if word in embed_model.wv.vocab]\n",
    "        if len(embeddings) == 0:\n",
    "            return None\n",
    "        word_sum = np.zeros(EMBED_SIZE, dtype='float64')\n",
    "        word_count = 0\n",
    "        for word in embeddings:\n",
    "            word_sum += word\n",
    "            word_count += 1\n",
    "        return word_sum / word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get POS tags from spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.attrs import POS\n",
    "\n",
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos2idx = {}\n",
    "def fill_pos_tags():\n",
    "    for edu in edu_reader:\n",
    "        doc = nlp(\" \".join(edu))\n",
    "        for token in doc:\n",
    "            if token.pos_ not in pos2idx:\n",
    "                pos2idx[token.pos_] = len(pos2idx)\n",
    "\n",
    "fill_pos_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vector(sentence):\n",
    "    embedding = get_sentence_embedding(sentence)\n",
    "    if embedding is None:\n",
    "        return None\n",
    "    doc = nlp(\" \".join(sentence))\n",
    "    root = [token for token in doc if token.head == token][0]\n",
    "    return np.r_[len(sentence), (np.arange(POS) == pos2idx[root.pos_]).astype(np.float64), embedding]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train connection classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "tqdm.monitor_interval = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_connected(lhs, rhs):\n",
    "    if lhs.parent != rhs.parent:\n",
    "        return False\n",
    "    if lhs.parent.nuclearity == RSTTree.MONONUCLEAR:\n",
    "        return True\n",
    "    assert lhs.type == 'nucleus' and rhs.type == 'nucleus'\n",
    "    return np.abs(lhs.index - rhs.index) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from random import shuffle\n",
    "\n",
    "def shuffled(x):\n",
    "    y = x[:]\n",
    "    shuffle(y)\n",
    "    return y\n",
    "\n",
    "def get_vector(lhs, rhs):\n",
    "    if lhs.text is None or rhs.text is None:\n",
    "        return None\n",
    "    lhs_vector = get_sentence_vector(lhs.text)\n",
    "    if lhs_vector is None:\n",
    "        return None\n",
    "    rhs_vector = get_sentence_vector(rhs.text)\n",
    "    if rhs_vector is None:\n",
    "        return None\n",
    "    return np.r_[lhs_vector, rhs_vector]\n",
    "\n",
    "def get_connection_set(trees):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    for tree in tqdm_notebook(trees):\n",
    "        \n",
    "        subtrees = tree.all_trees()\n",
    "        for subtree in subtrees:\n",
    "            if subtree.nuclearity == RSTTree.MONONUCLEAR:\n",
    "                pair = get_vector(subtree.nuclei[0], subtree.satellite)\n",
    "                if pair is None:\n",
    "                    continue\n",
    "                pairs.append(pair)\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                for lhs, rhs in zip(subtree.nuclei, subtree.nuclei[1:]):\n",
    "                    pair = get_vector(lhs, rhs)\n",
    "                    if pair is None:\n",
    "                        continue\n",
    "                    pairs.append(pair)\n",
    "                    labels.append(1)\n",
    "\n",
    "        for i, (left, right) in enumerate(product(shuffled(subtrees), shuffled(subtrees))):\n",
    "            if left == right or are_connected(left, right):\n",
    "                continue\n",
    "            if i > 30:\n",
    "                break\n",
    "            pair = get_vector(left, right)\n",
    "            if pair is None:\n",
    "                continue\n",
    "            pairs.append(pair)\n",
    "            labels.append(0)\n",
    "\n",
    "    shape = len(pairs), pairs[0].shape[0]\n",
    "    return np.concatenate(pairs).reshape(shape), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training connection data\n",
    "Do not run this cell unless you know what you are doing. It takes 10 minutes to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563decc19fbe4ddaa02346dbc17a6c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conn_train_X, conn_train_Y = get_connection_set(corpus_reader.load_train_trees())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / load training connection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('connection_train_set.pickle', 'wb') as handle:\n",
    "    pickle.dump((conn_train_X, conn_train_Y), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('connection_train_set.pickle', 'rb') as handle:\n",
    "    (conn_train_X, conn_train_Y) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test connection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c150cbaf76594f1b956fbd754c7ccfee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conn_test_X, conn_test_Y = get_connection_set(corpus_reader.load_test_trees())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / load test connection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('connection_test_set.pickle', 'wb') as handle:\n",
    "    pickle.dump((conn_test_X, conn_test_Y), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('connection_test_set.pickle', 'rb') as handle:\n",
    "    (conn_test_X, conn_test_Y) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_model = Sequential()\n",
    "connection_model.add(Dense(256, input_dim=conn_train_X.shape[1], activation='relu'))\n",
    "connection_model.add(Dropout(0.5))\n",
    "connection_model.add(Dense(128, activation='relu'))\n",
    "connection_model.add(Dropout(0.5))\n",
    "connection_model.add(Dense(64, activation='relu'))\n",
    "connection_model.add(Dropout(0.5))\n",
    "connection_model.add(Dense(1, activation='sigmoid'))\n",
    "connection_model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_model.fit(conn_train_X, conn_train_Y, batch_size=128, verbose=0, epochs=15)\n",
    "connection_model.save(\"connection_model.hs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3211138275902424, 0.8535051455712903]\n"
     ]
    }
   ],
   "source": [
    "score = connection_model.evaluate(conn_train_X, conn_train_Y, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7510689302794564, 0.7476099426044333]\n"
     ]
    }
   ],
   "source": [
    "score = connection_model.evaluate(conn_test_X, conn_test_Y, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train relation classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "def get_relation_set(trees, populate_relations = False, relation2idx = dict()):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    for tree in tqdm_notebook(trees):\n",
    "        \n",
    "        subtrees = tree.all_trees()\n",
    "        for subtree in subtrees:\n",
    "            \n",
    "            if subtree.relation is None:\n",
    "                continue\n",
    "            \n",
    "            if populate_relations and subtree.relation not in relation2idx:\n",
    "                relation2idx[subtree.relation] = len(relation2idx)\n",
    "            \n",
    "            elif not populate_relations and subtree.relation not in relation2idx.keys():\n",
    "                continue\n",
    "            \n",
    "            if subtree.nuclearity == RSTTree.MONONUCLEAR:\n",
    "                pair = get_vector(subtree.nuclei[0], subtree.satellite)\n",
    "                if pair is None:\n",
    "                    continue\n",
    "                pairs.append(pair)\n",
    "                labels.append(relation2idx[subtree.relation])\n",
    "            \n",
    "            else:\n",
    "                for lhs, rhs in zip(subtree.nuclei, subtree.nuclei[1:]):\n",
    "                    pair = get_vector(lhs, rhs)\n",
    "                    if pair is None:\n",
    "                        continue\n",
    "                    pairs.append(pair)\n",
    "                    labels.append(relation2idx[subtree.relation])\n",
    "\n",
    "    shape = len(pairs), pairs[0].shape[0]\n",
    "    return np.concatenate(pairs).reshape(shape), to_categorical(labels, num_classes=len(relation2idx)), relation2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training relation data\n",
    "Do not run this cell unless you know what you are doing. It takes 10 minutes to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d77efae8d5474b994bca60722e47f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-1672:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 148, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rel_train_X, rel_train_Y, relation2idx = get_relation_set(corpus_reader.load_train_trees(), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / load training relation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('relation_train_set.pickle', 'wb') as handle:\n",
    "    pickle.dump((rel_train_X, rel_train_Y, relation2idx), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('relation_train_set.pickle', 'rb') as handle:\n",
    "    (rel_train_X, rel_train_Y, relation2idx) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test relation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f227117eaf9346b7863f889823b6d859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rel_test_X, rel_test_Y, _ = get_relation_set(\n",
    "    corpus_reader.load_test_trees(),\n",
    "    populate_relations=False,\n",
    "    relation2idx=relation2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / load test relation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('relation_test_set.pickle', 'wb') as handle:\n",
    "    pickle.dump((rel_test_X, rel_test_Y), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('relation_test_set.pickle', 'rb') as handle:\n",
    "    (rel_test_X, rel_test_Y) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_model = Sequential()\n",
    "relation_model.add(Dense(256, input_dim=rel_train_X.shape[1], activation='relu'))\n",
    "relation_model.add(Dropout(0.5))\n",
    "relation_model.add(Dense(128, activation='relu'))\n",
    "relation_model.add(Dropout(0.5))\n",
    "relation_model.add(Dense(64, activation='relu'))\n",
    "relation_model.add(Dropout(0.5))\n",
    "relation_model.add(Dense(rel_train_Y.shape[1], activation='softmax'))\n",
    "relation_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_model.fit(rel_train_X, rel_train_Y, batch_size=128, verbose=0, epochs=50)\n",
    "relation_model.save(\"relation_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.785708257890628, 0.532546631151794]\n"
     ]
    }
   ],
   "source": [
    "score = relation_model.evaluate(rel_train_X, rel_train_Y, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.512644358539888, 0.41736334399395053]\n"
     ]
    }
   ],
   "source": [
    "score = relation_model.evaluate(rel_test_X, rel_test_Y, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train nuclearity classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUCLEUS_L = [1, 0]\n",
    "NUCLEUS_R = [0, 1]\n",
    "NUCLEUS_B = [1, 1]\n",
    "\n",
    "def get_nuclearity_set(trees):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    for tree in tqdm_notebook(trees):\n",
    "        \n",
    "        subtrees = tree.all_trees()\n",
    "        for subtree in subtrees:\n",
    "            \n",
    "            if subtree.nuclearity == RSTTree.MONONUCLEAR:\n",
    "                pair = get_vector(subtree.nuclei[0], subtree.satellite)\n",
    "                if pair is None:\n",
    "                    continue\n",
    "                pairs.append(pair)\n",
    "                label = NUCLEUS_L if subtree.nuclei[0].span[1] <= subtree.satellite.span[0] else NUCLEUS_R\n",
    "                labels.append(label)\n",
    "            \n",
    "            else:\n",
    "                for lhs, rhs in zip(subtree.nuclei, subtree.nuclei[1:]):\n",
    "                    pair = get_vector(lhs, rhs)\n",
    "                    if pair is None:\n",
    "                        continue\n",
    "                    pairs.append(pair)\n",
    "                    labels.append(NUCLEUS_B)\n",
    "\n",
    "    shape = len(pairs), pairs[0].shape[0]\n",
    "    return np.concatenate(pairs).reshape(shape), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare nuclearity relation data\n",
    "Do not run this cell unless you know what you are doing. It takes 10 minutes to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89047e115844c8ab1b598cfdae31dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nuc_train_X, nuc_train_Y = get_nuclearity_set(corpus_reader.load_train_trees())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / load nuclearity training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nuclearity_train_set.pickle', 'wb') as handle:\n",
    "    pickle.dump((nuc_train_X, nuc_train_Y), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nuclearity_train_set.pickle', 'rb') as handle:\n",
    "    (nuc_train_X, nuc_train_Y) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare nuclearity test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150d2876d4ea462ca2b22ad0bbdb00a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nuc_test_X, nuc_test_Y = get_nuclearity_set(corpus_reader.load_test_trees())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / load nuclearity test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nuclearity_test_set.pickle', 'wb') as handle:\n",
    "    pickle.dump((nuc_test_X, nuc_test_Y), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nuclearity_test_set.pickle', 'rb') as handle:\n",
    "    (nuc_test_X, nuc_test_Y) = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclearity_model = Sequential()\n",
    "nuclearity_model.add(Dense(256, input_dim=nuc_train_X.shape[1], activation='relu'))\n",
    "nuclearity_model.add(Dropout(0.5))\n",
    "nuclearity_model.add(Dense(128, activation='relu'))\n",
    "nuclearity_model.add(Dropout(0.5))\n",
    "nuclearity_model.add(Dense(64, activation='relu'))\n",
    "nuclearity_model.add(Dropout(0.5))\n",
    "nuclearity_model.add(Dense(nuc_train_Y.shape[1], activation='softmax'))\n",
    "nuclearity_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclearity_model.fit(nuc_train_X, nuc_train_Y, batch_size=128, verbose=0, epochs=10)\n",
    "nuclearity_model.save(\"nuclearity_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5087376583437072, 0.9509706889988581]\n"
     ]
    }
   ],
   "source": [
    "score = nuclearity_model.evaluate(nuc_train_X, nuc_train_Y, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6296352088374871, 0.917843389113234]\n"
     ]
    }
   ],
   "source": [
    "score = nuclearity_model.evaluate(nuc_test_X, nuc_test_Y, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Tree construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1391,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = ['Spencer', 'J', '.', 'Volk', ',', 'president', 'and', 'chief', 'operating', 'officer', 'of', 'this', 'consumer', 'and', 'industrial', 'products', 'company', ',', 'was', 'elected', 'a', 'director', '.']\n",
    "sent2 = ['Mr', '.', 'Volk', ',', '55', 'years', 'old', ',', 'succeeds', 'Duncan', 'Dwight', ',']\n",
    "sent3 = ['who', 'retired', 'in', 'September', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2relation = { index : relation for relation, index in relation2idx.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_once(tree_list):\n",
    "    best_connection = 0\n",
    "    best_connection_index = -1\n",
    "    best_vector = None\n",
    "    for i, (lhs, rhs) in enumerate(zip(tree_list, tree_list[1:])):\n",
    "        vector = get_vector(lhs, rhs)\n",
    "        if vector is None:\n",
    "            continue\n",
    "        connection = connection_model.predict(np.expand_dims(vector, axis=0))[0][0]\n",
    "        #print(connection)\n",
    "        if connection > best_connection:\n",
    "            best_connection = connection\n",
    "            best_connection_index = i\n",
    "            best_vector = vector\n",
    "\n",
    "    if best_vector is None:\n",
    "        return tree_list\n",
    "\n",
    "    lhs = tree_list[best_connection_index]\n",
    "    rhs = tree_list[best_connection_index + 1]\n",
    "\n",
    "    relation = relation_model.predict_classes(np.expand_dims(best_vector, axis=0))[0]\n",
    "    relation = idx2relation[relation]\n",
    "    #print(relation)\n",
    "\n",
    "    nuclearity = nuclearity_model.predict(np.expand_dims(best_vector, axis=0))[0]\n",
    "    nuclearity = np.round(nuclearity).astype(np.int)\n",
    "    #print(nuclearity)\n",
    "\n",
    "    nuclei = []\n",
    "    satellite = None\n",
    "    if nuclearity[0] == 0:\n",
    "        satellite = lhs\n",
    "    else:\n",
    "        nuclei.append(lhs)\n",
    "    if nuclearity[1] == 0:\n",
    "        satellite = rhs\n",
    "    else:\n",
    "        nuclei.append(rhs)\n",
    "\n",
    "    new_tree = RSTTree.from_trees(relation, nuclei, satellite)\n",
    "    new_tree.construct_text()\n",
    "    new_tree_list = tree_list[:best_connection_index]\n",
    "    new_tree_list.append(new_tree)\n",
    "    new_tree_list += tree_list[best_connection_index + 2:]\n",
    "    return new_tree_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1434,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_list = [RSTTree.from_text(sent1, 1, 1),\n",
    "             RSTTree.from_text(sent2, 2, 2),\n",
    "             RSTTree.from_text(sent3, 3, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(tree_list):\n",
    "    prev_length = len(tree_list)\n",
    "    while True:\n",
    "        tree_list = merge_once(tree_list)\n",
    "        if len(tree_list) == prev_length:\n",
    "            return tree_list\n",
    "        prev_length = len(tree_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( root (span 1 3) \n",
      "  ( nucleus (leaf 1) (rel2par span) (text Spencer J . Volk , president and chief operating officer of this consumer and industrial products company , was elected a director .) )\n",
      "  ( satellite (span 2 3) (rel2par elaboration-additional)   \n",
      "    ( nucleus (leaf 2) (rel2par span) (text Mr . Volk , 55 years old , succeeds Duncan Dwight ,) )  \n",
      "    ( satellite (leaf 3) (rel2par elaboration-additional-e) (text who retired in September .) )  \n",
      ")\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpraid/anaconda3/envs/advanced-nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "result = merge(tree_list)\n",
    "print(result[0].output_lisp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:advanced-nlp]",
   "language": "python",
   "name": "conda-env-advanced-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
>>>>>>> e4f1ff1cf4ce6461548e9abad2634a8ababbe79f
